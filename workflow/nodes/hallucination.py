"""
Hallucination Check Node (CRAG)
ìƒì„±ëœ ë‹µë³€ì´ ë¬¸ì„œ ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦í•˜ëŠ” ë…¸ë“œ
"""

import os
import logging
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain_core.messages import AIMessage
from pydantic import BaseModel, Field
from dotenv import load_dotenv


from workflow.state import MVPWorkflowState, QualityCheckResult

load_dotenv()

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class HallucinationCheckResult(BaseModel):
    """í™˜ê° ì²´í¬ ê²°ê³¼"""
    is_grounded: bool = Field(description="Whether the answer is grounded in the documents")
    hallucination_score: float = Field(description="Hallucination score (0.0=no hallucination, 1.0=complete hallucination)")
    problematic_claims: List[str] = Field(description="List of claims not supported by documents")
    supported_claims: List[str] = Field(description="List of claims supported by documents")
    reasoning: str = Field(description="Detailed reasoning for the assessment")


class HallucinationCheckNode:
    """ë‹µë³€ì˜ í™˜ê°(hallucination) ì²´í¬ ë…¸ë“œ - CRAG íŒ¨í„´"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ì§ì ‘ ìƒì„±
        self.llm = ChatOpenAI(
            model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
            temperature=0,  # ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´ temperature 0
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # í™˜ê° ì²´í¬ ì„ê³„ê°’ (.envì—ì„œ ì½ê¸°)
        self.threshold = float(os.getenv("CRAG_HALLUCINATION_THRESHOLD", "0.7"))
        
        # í™˜ê° ì²´í¬ í”„ë¡¬í”„íŠ¸
        self.hallucination_check_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a strict fact-checker for a RAG system.
Your task is to verify if the generated answer is fully grounded in the provided documents.

CRITICAL DISTINCTION - NOT Hallucinations:
âœ“ Stating "information is not in the documents" or "documents don't specify"
âœ“ Admitting lack of specific details
âœ“ Saying "cannot determine from provided documents"
âœ“ Being conservative about what can be claimed
âœ“ Reference numbers like [1], [2], etc. are citation markers, NOT content
âœ“ "References" section at the end is proper citation format
These are GOOD, GROUNDED responses that should be marked as valid.

Evaluation Process:
1. Extract all factual claims from the answer
2. Check each claim against the source documents
3. Identify unsupported claims (hallucinations)
4. Calculate hallucination score

Hallucination Score Guidelines:
- 0.0: All claims are directly supported by documents OR answer correctly states information is not available
- 0.1-0.3: Minor unsupported details that don't affect main answer
- 0.4-0.6: Some unsupported claims but core answer is correct
- 0.7-0.9: Major unsupported claims that affect answer quality
- 1.0: Answer is completely fabricated

Be STRICT in evaluation of positive claims:
- Claims must be EXPLICITLY stated or clearly implied in documents
- Reasonable inferences are acceptable only if strongly supported
- Technical specifications must match exactly
- Numbers, dates, procedures must be precise

Mark as problematic ONLY if answer makes false positive claims:
- Specific numbers not in documents (but claiming they are)
- Procedures or steps not mentioned (but presented as fact)
- Technical details not verified (but stated as true)
- Conclusions not supported by evidence (but claimed as certain)

Remember: An answer that admits "I don't have that information" is being honest, not hallucinating."""),
            ("human", """Original Query: {query}

Generated Answer:
{answer}

Source Documents:
{documents}

Evaluate if the answer is grounded in the documents.
List all claims and check each against the sources.""")
        ])
    
    
    def _format_documents_for_checking(self, documents: List[Document]) -> str:
        """
        ì²´í¬ìš© ë¬¸ì„œ í¬ë§·íŒ…
        
        Args:
            documents: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í¬ë§·íŒ…ëœ ë¬¸ì„œ í…ìŠ¤íŠ¸
        """
        if not documents:
            return "No source documents available"
        
        formatted = []
        for idx, doc in enumerate(documents, 1):
            # Document ê°ì²´ íƒ€ì… ê²€ì¦ ë° ë³µì›
            if isinstance(doc, str):
                # LangGraphê°€ Documentë¥¼ stringìœ¼ë¡œ ì§ë ¬í™”í•œ ê²½ìš°
                try:
                    import json
                    doc_dict = json.loads(doc)
                    from langchain_core.documents import Document
                    doc = Document(
                        page_content=doc_dict.get("page_content", ""),
                        metadata=doc_dict.get("metadata", {})
                    )
                except (json.JSONDecodeError, TypeError):
                    logger.warning(f"[HALLUCINATION] Failed to parse document string at index {idx}")
                    continue
            elif isinstance(doc, dict):
                # LangGraph ì§ë ¬í™”ë¡œ dictê°€ ëœ ê²½ìš°
                from langchain_core.documents import Document
                doc = Document(
                    page_content=doc.get("page_content", ""),
                    metadata=doc.get("metadata", {})
                )
            elif not hasattr(doc, 'metadata') or not hasattr(doc, 'page_content'):
                # ì˜ëª»ëœ í˜•ì‹ì˜ ê°ì²´ì¸ ê²½ìš°
                logger.warning(f"[HALLUCINATION] Invalid document format at index {idx}: {type(doc)}")
                continue
            
            metadata = doc.metadata
            
            # ê¸°ë³¸ ë¬¸ì„œ ì •ë³´
            doc_text = f"""
Document {idx}:
- Source: {metadata.get('source', 'Unknown')}
- Page: {metadata.get('page', 'N/A')}
- Category: {metadata.get('category', 'Unknown')}"""
            
            # Human feedbackì´ ìˆìœ¼ë©´ ìµœìš°ì„ ìœ¼ë¡œ ì¶”ê°€ (íƒ€ì… ì•ˆì „ì„± ë³´ì¥)
            human_feedback = metadata.get('human_feedback')
            if human_feedback and isinstance(human_feedback, str) and human_feedback.strip():
                doc_text += f"\n- Human Verified Content: {human_feedback}"
            
            # Entity ì •ë³´ê°€ ìˆìœ¼ë©´ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì¶”ê°€ (íƒ€ì… ì•ˆì „ì„± ë³´ì¥)
            entity = metadata.get('entity')
            if entity:
                # entityê°€ dictionaryê°€ ì•„ë‹Œ ê²½ìš° ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                if not isinstance(entity, dict):
                    doc_text += f"\n- Entity Info: {str(entity)}"
                else:
                    category = metadata.get('category', '')
                    entity_type = entity.get('type', '')
                    
                    # 'ë˜‘ë”±ì´' íƒ€ì… ì²˜ë¦¬
                    if entity_type == 'ë˜‘ë”±ì´':
                        doc_text += "\n- PPT Embedded Document (ë˜‘ë”±ì´):"
                        title = entity.get('title')
                        if title and isinstance(title, str):
                            doc_text += f"\n  Title: {title}"
                        details = entity.get('details')
                        if details and isinstance(details, str):
                            doc_text += f"\n  Details: {details}"
                        keywords = entity.get('keywords')
                        if keywords and isinstance(keywords, list):
                            doc_text += f"\n  Keywords: {', '.join(str(k) for k in keywords)}"
                        hypothetical_questions = entity.get('hypothetical_questions')
                        if hypothetical_questions and isinstance(hypothetical_questions, list):
                            questions_to_show = hypothetical_questions[:3]
                            doc_text += f"\n  Can Answer: {'; '.join(str(q) for q in questions_to_show)}"
                    elif category == 'table' and entity:
                        doc_text += "\n- Table Information:"
                        title = entity.get('title')
                        if title and isinstance(title, str):
                            doc_text += f"\n  Title: {title}"
                        details = entity.get('details')
                        if details and isinstance(details, str):
                            doc_text += f"\n  Details: {details}"
                        keywords = entity.get('keywords')
                        if keywords and isinstance(keywords, list):
                            doc_text += f"\n  Keywords: {', '.join(str(k) for k in keywords)}"
                    elif category == 'figure' and entity:
                        doc_text += "\n- Figure Information:"
                        title = entity.get('title')
                        if title and isinstance(title, str):
                            doc_text += f"\n  Title: {title}"
                        details = entity.get('details')
                        if details and isinstance(details, str):
                            doc_text += f"\n  Description: {details}"
            
            # ìº¡ì…˜ì´ ìˆìœ¼ë©´ ì¶”ê°€
            if metadata.get('caption'):
                doc_text += f"\n- Caption: {metadata['caption']}"
            
            # ì›ë³¸ ì½˜í…ì¸ 
            doc_text += f"\n- Full Content:\n{doc.page_content}\n---"
            
            formatted.append(doc_text)
        
        return "\n".join(formatted)
    
    def _check_entity_mentions(self, answer: str, documents: List[Document]) -> Dict[str, Any]:
        """
        ë‹µë³€ì—ì„œ ì¤‘ìš”í•œ entity typeë“¤ì´ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
        
        Args:
            answer: ìƒì„±ëœ ë‹µë³€
            documents: ì›ë³¸ ë¬¸ì„œë“¤
            
        Returns:
            entity ì–¸ê¸‰ ì²´í¬ ê²°ê³¼
        """
        # ë˜‘ë”±ì´ entityê°€ ìˆëŠ”ì§€ í™•ì¸
        has_ddokddak = False
        ddokddak_titles = []
        
        for doc in documents:
            if not isinstance(doc, Document):
                continue
            
            metadata = doc.metadata or {}
            entity = metadata.get("entity", {})
            
            if isinstance(entity, dict):
                entity_type = entity.get("type", "")
                if entity_type == "ë˜‘ë”±ì´":
                    has_ddokddak = True
                    title = entity.get("title", "")
                    if title and title not in ddokddak_titles:
                        ddokddak_titles.append(title)
        
        # ë˜‘ë”±ì´ entityê°€ ìˆëŠ” ê²½ìš° ë‹µë³€ì—ì„œ ì–¸ê¸‰í–ˆëŠ”ì§€ í™•ì¸
        if has_ddokddak:
            # ë‹µë³€ì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ì–¸ê¸‰ ì—¬ë¶€ í™•ì¸
            mention_keywords = ["ë˜‘ë”±ì´", "PPT", "ì‚½ì… ë¬¸ì„œ", "embedded", "í”„ë ˆì  í…Œì´ì…˜"]
            mentioned = any(keyword in answer for keyword in mention_keywords)
            
            if not mentioned:
                logger.warning(f"[HALLUCINATION] ë˜‘ë”±ì´ entityê°€ {len(ddokddak_titles)}ê°œ ìˆì§€ë§Œ ë‹µë³€ì—ì„œ ì–¸ê¸‰ë˜ì§€ ì•ŠìŒ")
                logger.warning(f"[HALLUCINATION] ë˜‘ë”±ì´ ë¬¸ì„œ ì œëª©: {', '.join(ddokddak_titles)}")
                
                return {
                    "has_special_entity": True,
                    "entity_mentioned": False,
                    "missing_entity_type": "ë˜‘ë”±ì´ (PPT ì‚½ì… ë¬¸ì„œ)",
                    "entity_titles": ddokddak_titles,
                    "warning_message": f"ë¬¸ì„œì— PPT ì‚½ì… ë¬¸ì„œ(ë˜‘ë”±ì´) {len(ddokddak_titles)}ê°œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë‚˜ ë‹µë³€ì—ì„œ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }
            else:
                logger.info(f"[HALLUCINATION] ë˜‘ë”±ì´ entityê°€ ì ì ˆíˆ ì–¸ê¸‰ë¨")
                return {
                    "has_special_entity": True,
                    "entity_mentioned": True,
                    "entity_type": "ë˜‘ë”±ì´ (PPT ì‚½ì… ë¬¸ì„œ)"
                }
        
        return {
            "has_special_entity": False
        }
    
    def __call__(self, state: MVPWorkflowState) -> Dict[str, Any]:
        """
        ë…¸ë“œ ì‹¤í–‰
        
        Args:
            state: ì›Œí¬í”Œë¡œìš° ìƒíƒœ
            
        Returns:
            ì—…ë°ì´íŠ¸ëœ ìƒíƒœ í•„ë“œ
        """
        logger.info(f"[HALLUCINATION] Node started")
        
        try:
            # ì²´í¬í•  ë‹µë³€ ê°€ì ¸ì˜¤ê¸°
            answer_to_check = state.get("intermediate_answer") or state.get("final_answer")
            
            if not answer_to_check:
                return {
                    "hallucination_check": {
                        "is_valid": False,
                        "score": 1.0,
                        "reason": "No answer to check",
                        "suggestions": ["Generate answer first"],
                        "needs_retry": False
                    },
                    "warnings": ["No answer available for hallucination check"]
                }
            
            # ì›ë³¸ ì¿¼ë¦¬
            query = state["query"]
            
            # ì‚¬ìš©ëœ ë¬¸ì„œë“¤
            documents = state.get("documents", [])
            
            # CRITICAL: documentsê°€ Noneì´ë©´ ì¦‰ì‹œ ì‹¤íŒ¨
            if documents is None:
                raise ValueError(
                    "CRITICAL ERROR: documents is None in hallucination check. "
                    "Previous nodes must provide documents list, not None."
                )
            
            # CRITICAL: documentsê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë©´ ì¦‰ì‹œ ì‹¤íŒ¨
            if not documents:
                raise ValueError(
                    "CRITICAL ERROR: Empty documents list in hallucination check. "
                    "Retrieval must provide at least one document. "
                    "Cannot verify answer without source documents."
                )
            
            # ë¬¸ì„œ í¬ë§·íŒ…
            formatted_docs = self._format_documents_for_checking(documents)
            
            # LLMì„ ì‚¬ìš©í•œ í™˜ê° ì²´í¬
            structured_llm = self.llm.with_structured_output(
                HallucinationCheckResult
            )
            
            check_result = structured_llm.invoke(
                self.hallucination_check_prompt.format_messages(
                    query=query,
                    answer=answer_to_check,
                    documents=formatted_docs
                )
            )
            
            # ì¬ì‹œë„ í•„ìš” ì—¬ë¶€ ê²°ì •
            needs_retry = check_result.hallucination_score > self.threshold
            
            # í™˜ê° ì²´í¬ ê²°ê³¼ ìƒì„¸ ì •ë³´ ë¡œê¹…
            logger.info(f"[HALLUCINATION] Score: {check_result.hallucination_score:.3f} | Grounded: {check_result.is_grounded}")
            if check_result.problematic_claims:
                problem_count = len(check_result.problematic_claims)
                problems_preview = ' | '.join([claim[:30] + '...' if len(claim) > 30 else claim for claim in check_result.problematic_claims[:2]])
                logger.info(f"[HALLUCINATION] {problem_count} problematic claims: {problems_preview}")
            if check_result.supported_claims:
                supported_count = len(check_result.supported_claims)
                logger.info(f"[HALLUCINATION] {supported_count} supported claims verified")
            
            # QualityCheckResult í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            # is_validëŠ” í™˜ê° ì ìˆ˜ê°€ threshold ì´í•˜ë©´ True (is_groundedëŠ” ì°¸ê³ ìš©)
            quality_check: QualityCheckResult = {
                "is_valid": check_result.hallucination_score <= self.threshold,
                "score": 1.0 - check_result.hallucination_score,  # ì‹ ë¢°ë„ ì ìˆ˜ë¡œ ë³€í™˜
                "reason": check_result.reasoning,
                "suggestions": check_result.problematic_claims if check_result.problematic_claims else [],
                "needs_retry": needs_retry
            }
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            metadata = state.get("metadata", {})
            metadata["hallucination_check"] = {
                "hallucination_score": check_result.hallucination_score,
                "is_grounded": check_result.is_grounded,
                "problematic_claims": check_result.problematic_claims,
                "supported_claims": check_result.supported_claims,
                "threshold": self.threshold
            }
            
            # Entity ì–¸ê¸‰ ì²´í¬ (íŠ¹íˆ ë˜‘ë”±ì´)
            entity_check = self._check_entity_mentions(answer_to_check, documents)
            if entity_check.get("has_special_entity"):
                metadata["entity_mention_check"] = entity_check
                
                # ë˜‘ë”±ì´ê°€ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ê²½ìš° ê²½ê³ 
                if not entity_check.get("entity_mentioned", True):
                    warning_msg = entity_check.get("warning_message", "íŠ¹ìˆ˜ entityê°€ ë‹µë³€ì—ì„œ ì–¸ê¸‰ë˜ì§€ ì•ŠìŒ")
                    logger.warning(f"[HALLUCINATION] {warning_msg}")
            
            # ê²½ê³  ì¶”ê°€ (í•„ìš”ì‹œ)
            warnings = []
            if check_result.hallucination_score > 0.5:
                warnings.append(f"High hallucination score: {check_result.hallucination_score:.2f}")
            
            # ë©”ì‹œì§€ ìƒì„± - í™˜ê° ê²€ì¦ ê³¼ì • ìƒì„¸ ì •ë³´
            messages = []
            
            # 1. ê²€ì¦ ì‹œì‘
            messages.append(
                AIMessage(content="ğŸ” í™˜ê° ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            )
            
            # 2. ê²€ì¦ í•­ëª©ë³„ ì ìˆ˜
            total_claims = len(check_result.supported_claims) + len(check_result.problematic_claims)
            grounding_rate = (len(check_result.supported_claims) / total_claims * 100) if total_claims > 0 else 100
            
            messages.append(
                AIMessage(content=f"""ğŸ“Š ê²€ì¦ ê²°ê³¼ ìƒì„¸:
  â€¢ ì „ì²´ ì£¼ì¥: {total_claims}ê°œ ê²€ì¦
  â€¢ ë¬¸ì„œ í™•ì¸ë¨: {len(check_result.supported_claims)}ê°œ âœ…
  â€¢ ë¬¸ì„œ ë¯¸í™•ì¸: {len(check_result.problematic_claims)}ê°œ âš ï¸
  â€¢ ë¬¸ì„œ ê·¼ê±°ìœ¨: {grounding_rate:.0f}%
  â€¢ í™˜ê° ìˆ˜ì¤€: {check_result.hallucination_score:.0%} (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)""")
            )
            
            # 3. ì¢…í•© ì ìˆ˜ì™€ ê¸°ì¤€
            messages.append(
                AIMessage(content=f"ğŸ“ˆ í™˜ê° ì ìˆ˜: {check_result.hallucination_score:.0%} (ê¸°ì¤€: <{self.threshold:.0%})")
            )
            
            # 4. ê²€ì¦ ê²°ê³¼
            retry_count = state.get("retry_count", 0)
            max_retries = int(os.getenv("CRAG_MAX_RETRIES", "3"))
            if quality_check["is_valid"]:
                messages.append(
                    AIMessage(content="âœ… í™˜ê° ê²€ì¦ í†µê³¼ - ë‹µë³€ì´ ë¬¸ì„œ ë‚´ìš©ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤")
                )
            else:
                if needs_retry and retry_count < max_retries:
                    messages.append(
                        AIMessage(content=f"âš ï¸ í™˜ê° ê°ì§€ - ì¬ìƒì„± í•„ìš” (ì‹œë„ {retry_count+1}/{max_retries})")
                    )
                else:
                    messages.append(
                        AIMessage(content="âŒ í™˜ê° ê²€ì¦ ì‹¤íŒ¨ - ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                    )
            
            return {
                "messages": messages,  # ë©”ì‹œì§€ ì¶”ê°€
                "hallucination_check": quality_check,
                "should_retry": needs_retry,
                "metadata": metadata,
                "warnings": warnings  # Always return list, never None
            }
            
        except Exception as e:
            logger.error(f"[HALLUCINATION] Node failed: {str(e)}")
            return {
                "error": f"Hallucination check failed: {str(e)}",
                "workflow_status": "failed",
                "warnings": [f"Hallucination check error: {str(e)}"]
            }
    
    def invoke(self, state: MVPWorkflowState) -> Dict[str, Any]:
        """ë™ê¸° ì‹¤í–‰ (LangGraph í˜¸í™˜ì„±)"""
        logger.debug(f"[HALLUCINATION] Invoke called (sync wrapper)")
        return self.__call__(state)