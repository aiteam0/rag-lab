"""
Planning Agent Node
ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì„œë¸ŒíƒœìŠ¤í¬ë¡œ ë¶„í•´í•˜ëŠ” ê³„íš ë…¸ë“œ
"""

import os
import logging
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import AIMessage
from pydantic import BaseModel, Field
from dotenv import load_dotenv
from workflow.state import MVPWorkflowState, SubtaskState
import uuid
import nest_asyncio

# Apply nest_asyncio to allow nested event loops
nest_asyncio.apply()

load_dotenv()

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class Subtask(BaseModel):
    """ì„œë¸ŒíƒœìŠ¤í¬ ìŠ¤í‚¤ë§ˆ"""
    query: str = Field(description="ì„œë¸ŒíƒœìŠ¤í¬ë¥¼ ìœ„í•œ êµ¬ì²´ì ì¸ ì¿¼ë¦¬")
    priority: int = Field(description="ìš°ì„ ìˆœìœ„ (1-5, 1ì´ ê°€ì¥ ë†’ìŒ)", ge=1, le=5)
    dependencies: List[str] = Field(default_factory=list, description="ì˜ì¡´í•˜ëŠ” ë‹¤ë¥¸ ì„œë¸ŒíƒœìŠ¤í¬ ì¸ë±ìŠ¤")
    search_language: str = Field(default="korean", description="ê²€ìƒ‰ ì–¸ì–´ (korean/english)")


class ExecutionPlan(BaseModel):
    """ì‹¤í–‰ ê³„íš ìŠ¤í‚¤ë§ˆ"""
    subtasks: List[Subtask] = Field(description="ì„œë¸ŒíƒœìŠ¤í¬ ëª©ë¡")
    strategy: str = Field(description="ì‹¤í–‰ ì „ëµ ì„¤ëª…")
    expected_complexity: str = Field(description="ì˜ˆìƒ ë³µì¡ë„ (simple/moderate/complex)")


class PlanningAgentNode:
    """ì¿¼ë¦¬ë¥¼ ì„œë¸ŒíƒœìŠ¤í¬ë¡œ ë¶„í•´í•˜ëŠ” ê³„íš ë…¸ë“œ"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.llm = ChatOpenAI(
            model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
            temperature=0,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # ìµœëŒ€ ì„œë¸ŒíƒœìŠ¤í¬ ìˆ˜ë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸°
        self.max_subtasks = int(os.getenv("LANGGRAPH_PLANNING_MAX_SUBTASKS", "5"))
        
        self.planning_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a query planning expert for a RAG system about automobile manufacturing.
Your task is to break down complex user queries into manageable subtasks.

Rules:
1. Create between 1 and {max_subtasks} subtasks maximum
2. Each subtask should be specific and answerable
3. Order subtasks by logical dependencies
4. Keep subtasks focused and atomic
5. Identify whether Korean or English search would be more effective for each subtask
6. For vehicle-specific queries, prefer Korean language
7. For technical specifications, consider using English

âš ï¸ CRITICAL: DO NOT ADD FORMAT SPECIFICATIONS
Create subtasks ONLY for what the user explicitly requested.
DO NOT add format specifications (tables, lists, charts, images) unless explicitly mentioned by the user.

STRICT RULES:
1. If user says "ì˜¤ì¼ ì‚¬ì–‘ì„ ì•Œë ¤ì£¼ì„¸ìš”" â†’ Create subtask: "ì˜¤ì¼ ì‚¬ì–‘"
2. If user says "í‘œë¡œ ì •ë¦¬ëœ ì˜¤ì¼ ì‚¬ì–‘" â†’ Create subtask: "í‘œë¡œ ì •ë¦¬ëœ ì˜¤ì¼ ì‚¬ì–‘"  
3. NEVER transform "ì˜¤ì¼ ì‚¬ì–‘" into "í‘œë¡œ ì •ë¦¬ëœ ì˜¤ì¼ ì‚¬ì–‘"
4. Focus on CONTENT retrieval, not PRESENTATION format

Filter Hint Keywords to PRESERVE ONLY IF PRESENT in original query:
- Table/Chart: IF user mentions "í‘œë¡œ", "í…Œì´ë¸”", "í‘œ í˜•íƒœ", "ì°¨íŠ¸" â†’ Keep these exact words
- Image/Figure: IF user mentions "ê·¸ë¦¼ìœ¼ë¡œ", "ì´ë¯¸ì§€", "ë„ì‹" â†’ Keep these exact words
- Page Reference: IF user mentions "Ní˜ì´ì§€" â†’ Keep exact page reference
- Entity Types: IF user mentions "êµ¬ì¡°ë„", "íšŒë¡œë„" â†’ Keep these exact words

EXAMPLES:
âœ… GOOD: "ì—”ì§„ ì˜¤ì¼ ì‚¬ì–‘" â†’ "ì—”ì§„ ì˜¤ì¼ ì‚¬ì–‘" (no format added)
âœ… GOOD: "í‘œë¡œ ì •ë¦¬ëœ ì˜¤ì¼ ì‚¬ì–‘" â†’ "í‘œë¡œ ì •ë¦¬ëœ ì˜¤ì¼ ì‚¬ì–‘" (preserved user's format)
âŒ BAD: "ì—”ì§„ ì˜¤ì¼ ì‚¬ì–‘" â†’ "í‘œë¡œ ì •ë¦¬ëœ ì˜¤ì¼ ì‚¬ì–‘" (added format not requested)

Consider the following when creating subtasks:
- Is this a simple lookup or complex analysis?
- Does it require multiple pieces of information?
- Are there dependencies between different parts?
- Which language would yield better search results?
- MOST IMPORTANT: Are filter hints (table, image, page) preserved in each subtask?

Examples:
- "ì°¨ëŸ‰ ì•ˆì „ ê¸°ëŠ¥ê³¼ ì—°ë¹„ëŠ”?" â†’ 2 subtasks (ì•ˆì „ ê¸°ëŠ¥, ì—°ë¹„)
- "How to change oil?" â†’ 1 subtask (oil change procedure)
- "ë¸Œë ˆì´í¬ ì‹œìŠ¤í…œ ì‘ë™ ì›ë¦¬ì™€ ì ê²€ ë°©ë²•" â†’ 2 subtasks (ì‘ë™ ì›ë¦¬, ì ê²€ ë°©ë²•)
- "í‘œë¡œ ì •ë¦¬ëœ ì—”ì§„ ì˜¤ì¼ ì‚¬ì–‘" â†’ "í‘œì— ë‚˜ì˜¨ ì—”ì§„ ì˜¤ì¼ì˜ ì‚¬ì–‘" (PRESERVE "í‘œ")"""),
            ("human", """Query: {query}

Break this down into subtasks. Consider:
1. What specific information is being requested?
2. Are there multiple distinct questions?
3. What order makes logical sense?
4. Which language (korean/english) would be best for each part?

Create an execution plan with subtasks.""")
        ])
    
    async def __call__(self, state: MVPWorkflowState) -> Dict[str, Any]:
        """
        ë…¸ë“œ ì‹¤í–‰
        
        Args:
            state: ì›Œí¬í”Œë¡œìš° ìƒíƒœ
            
        Returns:
            ì—…ë°ì´íŠ¸ëœ ìƒíƒœ í•„ë“œ
        """
        logger.info(f"[PLANNING] Node started")
        
        try:
            query = state["query"]
            logger.debug(f"[PLANNING] Processing query: '{query}'")
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ ë¶„ì„ ë° ì„œë¸ŒíƒœìŠ¤í¬ ìƒì„±
            logger.debug(f"[PLANNING] Creating structured LLM with max_subtasks={self.max_subtasks}")
            structured_llm = self.llm.with_structured_output(ExecutionPlan)
            
            logger.info(f"[PLANNING] Generating execution plan...")
            plan = await structured_llm.ainvoke(
                self.planning_prompt.format_messages(
                    query=query,
                    max_subtasks=self.max_subtasks
                )
            )
            logger.info(f"[PLANNING] Generated {len(plan.subtasks)} subtasks, strategy: {plan.strategy}")
            
            # ì„œë¸ŒíƒœìŠ¤í¬ë¥¼ ìƒíƒœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            subtasks = []
            for i, task in enumerate(plan.subtasks):
                subtask_state: SubtaskState = {
                    "id": str(uuid.uuid4()),
                    "query": task.query,
                    "priority": task.priority,
                    "dependencies": task.dependencies,
                    "status": "pending",
                    "result": None,
                    "error": None,
                    "documents": [],
                    "answer": None
                }
                subtasks.append(subtask_state)
                logger.debug(f"[PLANNING] Subtask {i}: '{task.query}' (priority: {task.priority})")
            
            # ìš°ì„ ìˆœìœ„ì™€ ì˜ì¡´ì„±ì— ë”°ë¼ ì •ë ¬
            original_order = [st["query"][:30] + "..." for st in subtasks]
            subtasks.sort(key=lambda x: (x["priority"], len(x["dependencies"])))
            sorted_order = [st["query"][:30] + "..." for st in subtasks]
            logger.debug(f"[PLANNING] Subtasks sorted by priority - before: {original_order}, after: {sorted_order}")
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            metadata = state.get("metadata", {})
            metadata["planning"] = {
                "total_subtasks": len(subtasks),
                "strategy": plan.strategy,
                "complexity": plan.expected_complexity
            }
            logger.info(f"[PLANNING] Planning completed - {len(subtasks)} subtasks, complexity: {plan.expected_complexity}")
            
            # ì„œë¸ŒíƒœìŠ¤í¬ ìƒì„¸ ì •ë³´ ë¡œê¹…
            for i, subtask_state in enumerate(subtasks):
                priority = subtask_state['priority'] 
                query_preview = subtask_state['query'][:60] + ('...' if len(subtask_state['query']) > 60 else '')
                logger.info(f"[PLANNING] Subtask {i+1}: [P:{priority}] \"{query_preview}\"")
            
            # ë©”ì‹œì§€ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)
            messages = [
                AIMessage(content=f"ğŸ“‹ ì¿¼ë¦¬ë¥¼ {len(subtasks)}ê°œì˜ ì„œë¸ŒíƒœìŠ¤í¬ë¡œ ë¶„í•´í–ˆìŠµë‹ˆë‹¤."),
                AIMessage(content=f"ğŸ¯ ì‹¤í–‰ ì „ëµ: {plan.strategy}")
            ]
            
            result = {
                "messages": messages,
                "subtasks": subtasks,
                "current_subtask_idx": 0,
                "metadata": metadata,
                "workflow_status": "running",
                "current_node": "planning"
            }
            logger.info(f"[PLANNING] Node completed successfully")
            return result
            
        except Exception as e:
            logger.error(f"[PLANNING] Planning failed: {str(e)}")
            return {
                "error": f"Planning failed: {str(e)}",
                "workflow_status": "failed"
            }
    
    def invoke(self, state: MVPWorkflowState) -> Dict[str, Any]:
        """ë™ê¸° ì‹¤í–‰ (LangGraph í˜¸í™˜ì„±)"""
        logger.debug(f"[PLANNING] Invoke called (sync wrapper)")
        
        import asyncio
        from concurrent.futures import ThreadPoolExecutor
        
        try:
            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
            loop = asyncio.get_running_loop()
            logger.debug(f"[PLANNING] Event loop detected, using ThreadPoolExecutor")
        except RuntimeError:
            # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•˜ì—¬ ì‹¤í–‰
            logger.debug(f"[PLANNING] No event loop, creating new one")
            return asyncio.run(self.__call__(state))
        else:
            # ì´ë¯¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì´ë©´ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            with ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(asyncio.run, self.__call__(state))
                return future.result()