"""
Main Workflow Graph
LangGraph ê¸°ë°˜ P-E-O íŒ¨í„´ ì›Œí¬í”Œë¡œìš°
"""

import os
import logging
from typing import Dict, Any, List, Optional
from pathlib import Path
from datetime import datetime
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.errors import GraphRecursionError
from langchain_core.documents import Document
from langchain_core.messages import AIMessage
from dotenv import load_dotenv

load_dotenv()

# í™˜ê²½ë³€ìˆ˜ ì½ê¸° (ë‹¨ 2ê°œë§Œ!)
log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
log_file_path = os.getenv('LOG_FILE_PATH', '')  # ë¹„ì–´ìˆìœ¼ë©´ íŒŒì¼ ë¡œê¹… ë¹„í™œì„±í™”

# í•¸ë“¤ëŸ¬ ë¦¬ìŠ¤íŠ¸
handlers = []

# 1. ì½˜ì†” í•¸ë“¤ëŸ¬ (í•­ìƒ í™œì„±í™”)
console_handler = logging.StreamHandler()
console_handler.setFormatter(logging.Formatter(
    '%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    datefmt='%H:%M:%S'
))
handlers.append(console_handler)

# 2. íŒŒì¼ í•¸ë“¤ëŸ¬ (LOG_FILE_PATHê°€ ì„¤ì •ëœ ê²½ìš°ë§Œ)
if log_file_path:
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = Path(log_file_path).parent
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ (í…ŒìŠ¤íŠ¸ ì‹¤í–‰ë§ˆë‹¤ êµ¬ë¶„)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    file_name = Path(log_file_path).stem
    file_ext = Path(log_file_path).suffix
    actual_path = log_dir / f"{file_name}_{timestamp}{file_ext}"
    
    file_handler = logging.FileHandler(actual_path, encoding='utf-8')
    file_handler.setFormatter(logging.Formatter(
        '%(asctime)s [%(levelname)-8s] %(name)-40s %(filename)s:%(lineno)d - %(message)s'
    ))
    handlers.append(file_handler)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=getattr(logging, log_level),
    handlers=handlers,
    force=True  # ê¸°ì¡´ ì„¤ì • ë®ì–´ì“°ê¸°
)

# ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ì–µì œ (ìë™ ê²°ì •)
third_party_level = 'DEBUG' if log_level == 'DEBUG' else 'WARNING'
for lib in ['httpcore', 'openai', 'httpx', 'asyncio']:
    logging.getLogger(lib).setLevel(getattr(logging, third_party_level))

logger = logging.getLogger(__name__)

# íŒŒì¼ ë¡œê¹… í™œì„±í™” ì‹œ ì•ˆë‚´ ë©”ì‹œì§€
if log_file_path:
    logger.info(f"File logging enabled: {actual_path}")

# ë…¸ë“œë“¤ import
from workflow.state import MVPWorkflowState
from workflow.nodes.planning_agent import PlanningAgentNode
from workflow.nodes.subtask_executor import SubtaskExecutorNode
from workflow.nodes.retrieval import RetrievalNode
from workflow.nodes.synthesis import SynthesisNode
from workflow.nodes.hallucination import HallucinationCheckNode
from workflow.nodes.answer_grader import AnswerGraderNode
from workflow.tools.tavily_search import TavilySearchTool

# ìƒˆë¡œìš´ ë…¸ë“œë“¤ import (Query Routing í™œì„±í™”ì‹œ)
try:
    from workflow.nodes.query_router import QueryRouterNode
    from workflow.nodes.direct_response import DirectResponseNode
    # ContextEnhancementNode removed - using MessagesState for chat history
    ROUTING_AVAILABLE = True
except ImportError:
    logger.warning("Query routing nodes not found. Running in legacy mode.")
    ROUTING_AVAILABLE = False


class MVPWorkflowGraph:
    """MVP RAG ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„"""
    
    def __init__(self, checkpointer_path: Optional[str] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            checkpointer_path: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ (ì„ íƒ)
        """
        # Query Routing í™œì„±í™” í™•ì¸
        self.enable_routing = os.getenv("ENABLE_QUERY_ROUTING", "true").lower() == "true" and ROUTING_AVAILABLE
        
        if self.enable_routing:
            logger.info("Query routing enabled")
            # ìƒˆë¡œìš´ ë…¸ë“œë“¤ ì´ˆê¸°í™”
            self.query_router = QueryRouterNode()
            self.direct_response = DirectResponseNode()
            # ContextEnhancement removed - chat history flows through MessagesState
        else:
            logger.info("Query routing disabled, using legacy mode")
        
        # ê¸°ì¡´ ë…¸ë“œ ì´ˆê¸°í™”
        self.planning_node = PlanningAgentNode()
        self.subtask_executor = SubtaskExecutorNode()
        self.retrieval_node = RetrievalNode()
        self.synthesis_node = SynthesisNode()
        self.hallucination_check = HallucinationCheckNode()
        self.answer_grader = AnswerGraderNode()
        
        # Tavily ë„êµ¬ ì´ˆê¸°í™” (ì„ íƒì )
        try:
            self.tavily_tool = TavilySearchTool(max_results=3)
            self.use_tavily = True
        except ValueError:
            print("Warning: Tavily API key not found. Web search disabled.")
            self.tavily_tool = None
            self.use_tavily = False
        
        # ì²´í¬í¬ì¸í„° ì„¤ì • (ì„ íƒì )
        self.checkpointer = None
        if checkpointer_path:
            self.checkpointer = SqliteSaver.from_conn_string(checkpointer_path)
        
        # ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±
        self.graph = self._build_graph()
        
        # ì»´íŒŒì¼ëœ ê·¸ë˜í”„ with recursion limit
        compiled_graph = self.graph.compile(checkpointer=self.checkpointer)
        
        # Recursion limit ê³„ì‚° ë° ì ìš©
        # ì„œë¸ŒíƒœìŠ¤í¬ ìˆ˜ * 3 (executor, retrieval, search) + CRAG ì¬ì‹œë„ * 4 + ê¸°ë³¸ ë…¸ë“œ + ë²„í¼
        max_subtasks = int(os.getenv("LANGGRAPH_PLANNING_MAX_SUBTASKS", "5"))
        max_retries = int(os.getenv("CRAG_MAX_RETRIES", "3"))
        recursion_limit = (max_subtasks * 3) + (max_retries * 4) + 10 + 20
        
        # with_configë¥¼ ì‚¬ìš©í•˜ì—¬ recursion limit ì ìš©
        self.app = compiled_graph.with_config(recursion_limit=recursion_limit)
    
    def _build_graph(self) -> StateGraph:
        """ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±"""
        
        # StateGraph ìƒì„±
        workflow = StateGraph(MVPWorkflowState)
        
        # === Query Routingì´ í™œì„±í™”ëœ ê²½ìš° ===
        if self.enable_routing:
            # ìƒˆë¡œìš´ ë…¸ë“œë“¤ ì¶”ê°€
            workflow.add_node("query_router", self.query_router.invoke)
            workflow.add_node("direct_response", self.direct_response.invoke)
            # context_enhancement node removed
            
            # ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ë¥¼ query_routerë¡œ ì„¤ì •
            workflow.set_entry_point("query_router")
            
            # Query Routerì—ì„œì˜ ì¡°ê±´ë¶€ ë¼ìš°íŒ… (simplified)
            def route_query(state: MVPWorkflowState) -> str:
                """ì¿¼ë¦¬ íƒ€ì…ì— ë”°ë¥¸ ë¼ìš°íŒ… (simple or rag_required only)"""
                query_type = state.get("query_type", "rag_required")
                
                if query_type == "simple":
                    logger.info(f"[ROUTING] Simple query â†’ DirectResponse")
                    return "direct_response"
                else:  # rag_required
                    logger.info(f"[ROUTING] RAG required â†’ Planning")
                    return "planning"
            
            workflow.add_conditional_edges(
                "query_router",
                route_query,
                {
                    "direct_response": "direct_response",
                    "planning": "planning"
                }
            )
            
            # Direct ResponseëŠ” ë°”ë¡œ ì¢…ë£Œ
            workflow.add_edge("direct_response", END)
            
            # Context Enhancement removed - using MessagesState
        else:
            # === Query Routingì´ ë¹„í™œì„±í™”ëœ ê²½ìš° (ê¸°ì¡´ ë™ì‘) ===
            workflow.set_entry_point("planning")
        
        # === ê¸°ì¡´ ë…¸ë“œë“¤ ì¶”ê°€ (ê³µí†µ) ===
        workflow.add_node("planning", self.planning_node.invoke)
        workflow.add_node("subtask_executor", self.subtask_executor.invoke)
        workflow.add_node("retrieval", self.retrieval_node.invoke)
        workflow.add_node("synthesis", self.synthesis_node.invoke)
        workflow.add_node("hallucination_check", self.hallucination_check.invoke)
        workflow.add_node("answer_grader", self.answer_grader.invoke)
        
        # Tavily ê²€ìƒ‰ ë…¸ë“œ (ì„ íƒì )
        if self.use_tavily:
            workflow.add_node("web_search", self._web_search_node_sync)
        
        # === ì—£ì§€ ì •ì˜ (ê¸°ì¡´ í”Œë¡œìš°ëŠ” ë™ì¼) ===
        
        # Planning â†’ Subtask Executor
        workflow.add_edge("planning", "subtask_executor")
        
        # Subtask Executor â†’ Retrieval ë˜ëŠ” ì™„ë£Œ
        workflow.add_conditional_edges(
            "subtask_executor",
            self._should_continue_subtasks,
            {
                "continue": "retrieval",
                "complete": "synthesis",
                "failed": END
            }
        )
        
        # Retrieval â†’ Web Search (í•„ìš”ì‹œ) ë˜ëŠ” ë‹¤ìŒ ë‹¨ê³„
        if self.use_tavily:
            workflow.add_conditional_edges(
                "retrieval",
                self._should_web_search,
                {
                    "search": "web_search",
                    "continue": "subtask_executor"
                }
            )
            # Web Search â†’ Subtask Executor
            workflow.add_edge("web_search", "subtask_executor")
        else:
            # Tavily ì—†ìœ¼ë©´ ë°”ë¡œ ë‹¤ìŒ ì„œë¸ŒíƒœìŠ¤í¬ë¡œ
            workflow.add_edge("retrieval", "subtask_executor")
        
        # Synthesis â†’ Hallucination Check
        workflow.add_edge("synthesis", "hallucination_check")
        
        # Hallucination Check â†’ Answer Grader ë˜ëŠ” ì¬ì‹œë„
        workflow.add_conditional_edges(
            "hallucination_check",
            self._check_hallucination,
            {
                "valid": "answer_grader",
                "retry": "synthesis",
                "failed": END
            }
        )
        
        # Answer Grader â†’ ì™„ë£Œ ë˜ëŠ” ì¬ì‹œë„
        workflow.add_conditional_edges(
            "answer_grader",
            self._check_answer_quality,
            {
                "accept": END,
                "retry": "synthesis",
                "failed": END
            }
        )
        
        return workflow
    
    def _should_continue_subtasks(self, state: MVPWorkflowState) -> str:
        """ì„œë¸ŒíƒœìŠ¤í¬ ê³„ì† ì‹¤í–‰ ì—¬ë¶€ ê²°ì •"""
        logger.debug(f"[CONDITIONAL] _should_continue_subtasks() called")
        
        # ì—ëŸ¬ ì²´í¬
        if state.get("error"):
            logger.warning(f"[CONDITIONAL] Found error in state: {state.get('error')}")
            return "failed"
        
        # ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì²´í¬
        workflow_status = state.get("workflow_status")
        logger.debug(f"[CONDITIONAL] Workflow status: {workflow_status}")
        if workflow_status == "completed":
            logger.info(f"[CONDITIONAL] Workflow marked as completed")
            return "complete"
        
        # ì„œë¸ŒíƒœìŠ¤í¬ ì§„í–‰ ìƒí™© ì²´í¬
        subtasks = state.get("subtasks", [])
        current_idx = state.get("current_subtask_idx", 0)
        logger.debug(f"[CONDITIONAL] Subtasks count: {len(subtasks)}, current_idx: {current_idx}")
        
        # í˜„ì¬ ì²˜ë¦¬í•  ì„œë¸ŒíƒœìŠ¤í¬ê°€ ìˆëŠ”ì§€ í™•ì¸
        if current_idx >= len(subtasks):
            # ëª¨ë“  ì„œë¸ŒíƒœìŠ¤í¬ ì™„ë£Œ
            logger.info(f"[CONDITIONAL] All subtasks completed ({current_idx}/{len(subtasks)})")
            return "complete"
        
        # í˜„ì¬ ì„œë¸ŒíƒœìŠ¤í¬ ìƒíƒœ í™•ì¸
        if subtasks:
            current_subtask = subtasks[current_idx]
            current_status = current_subtask.get("status", "pending")
            logger.debug(f"[CONDITIONAL] Current subtask[{current_idx}] status: {current_status}")
            
            # retrieved ìƒíƒœë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ (subtask_executorê°€ ì¸ë±ìŠ¤ ì¦ê°€ ì²˜ë¦¬)
            if current_status == "retrieved":
                logger.info(f"[CONDITIONAL] Subtask[{current_idx}] retrieved, continuing to next")
                return "continue"
        
        logger.info(f"[CONDITIONAL] Continuing with subtask {current_idx}")
        return "continue"
    
    def _should_web_search(self, state: MVPWorkflowState) -> str:
        """ì›¹ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ ê²°ì •"""
        logger.debug(f"[CONDITIONAL] _should_web_search() called")
        
        if not self.use_tavily:
            logger.debug(f"[CONDITIONAL] Tavily not available, skipping web search")
            return "continue"
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ê²½ìš°
        documents = state.get("documents", [])
        doc_count = len(documents)
        logger.debug(f"[CONDITIONAL] Current document count: {doc_count}")
        
        if doc_count < 3:
            # ë¬¸ì„œê°€ 3ê°œ ë¯¸ë§Œì´ë©´ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
            logger.info(f"[CONDITIONAL] Insufficient documents ({doc_count} < 3), triggering web search")
            return "search"
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì›¹ ê²€ìƒ‰ ìš”ì²­ í™•ì¸
        metadata = state.get("metadata", {})
        require_web_search = metadata.get("require_web_search", False)
        logger.debug(f"[CONDITIONAL] Web search explicitly required: {require_web_search}")
        
        if require_web_search:
            logger.info(f"[CONDITIONAL] Web search explicitly required")
            return "search"
        
        logger.debug(f"[CONDITIONAL] Sufficient documents found, skipping web search")
        return "continue"
    
    def _check_hallucination(self, state: MVPWorkflowState) -> str:
        """í™˜ê° ì²´í¬ ê²°ê³¼ í™•ì¸"""
        logger.debug(f"[CONDITIONAL] _check_hallucination() called")
        
        # ì—ëŸ¬ ì²´í¬
        if state.get("error"):
            logger.warning(f"[CONDITIONAL] Found error in state: {state.get('error')}")
            return "failed"
        
        hallucination_check = state.get("hallucination_check", {})
        is_valid = hallucination_check.get("is_valid", False)
        needs_retry = hallucination_check.get("needs_retry", False)
        logger.debug(f"[CONDITIONAL] Hallucination check - valid: {is_valid}, needs_retry: {needs_retry}")
        
        # í™˜ê° ê²€ì‚¬ í†µê³¼
        if is_valid:
            logger.info(f"[CONDITIONAL] Hallucination check passed")
            return "valid"
        
        # ì¬ì‹œë„ í•„ìš”
        if needs_retry:
            # ì¬ì‹œë„ íšŸìˆ˜ ì²´í¬ (ì¦ê°€ëŠ” SynthesisNodeì—ì„œ ì²˜ë¦¬)
            retry_count = state.get("retry_count", 0)
            max_retries = int(os.getenv("CRAG_MAX_RETRIES", "3"))
            logger.debug(f"[CONDITIONAL] Current retry count: {retry_count}/{max_retries}")
            
            if retry_count < max_retries:
                logger.info(f"[CONDITIONAL] Hallucination check failed, will retry (current: {retry_count})")
                return "retry"
            else:
                logger.warning(f"[CONDITIONAL] Max retries reached for hallucination check")
        
        logger.error(f"[CONDITIONAL] Hallucination check failed permanently")
        return "failed"
    
    def _check_answer_quality(self, state: MVPWorkflowState) -> str:
        """ë‹µë³€ í’ˆì§ˆ ì²´í¬ ê²°ê³¼ í™•ì¸"""
        logger.debug(f"[CONDITIONAL] _check_answer_quality() called")
        
        # ì—ëŸ¬ ì²´í¬
        if state.get("error"):
            logger.warning(f"[CONDITIONAL] Found error in state: {state.get('error')}")
            return "failed"
        
        answer_grade = state.get("answer_grade", {})
        is_valid = answer_grade.get("is_valid", False)
        needs_retry = answer_grade.get("needs_retry", False)
        logger.debug(f"[CONDITIONAL] Answer grade - valid: {is_valid}, needs_retry: {needs_retry}")
        
        # í’ˆì§ˆ ê¸°ì¤€ í†µê³¼
        if is_valid:
            logger.info(f"[CONDITIONAL] Answer quality check passed")
            return "accept"
        
        # ì¬ì‹œë„ í•„ìš”
        if needs_retry:
            # ì¬ì‹œë„ íšŸìˆ˜ ì²´í¬ (ì¦ê°€ëŠ” SynthesisNodeì—ì„œ ì²˜ë¦¬)
            retry_count = state.get("retry_count", 0)
            max_retries = int(os.getenv("CRAG_MAX_RETRIES", "3"))
            logger.debug(f"[CONDITIONAL] Current retry count: {retry_count}/{max_retries}")
            
            if retry_count < max_retries:
                logger.info(f"[CONDITIONAL] Answer quality check failed, will retry (current: {retry_count})")
                return "retry"
            else:
                logger.warning(f"[CONDITIONAL] Max retries reached for answer quality check")
        
        logger.error(f"[CONDITIONAL] Answer quality check failed permanently")
        return "failed"
    
    async def _web_search_node(self, state: MVPWorkflowState) -> Dict[str, Any]:
        """ì›¹ ê²€ìƒ‰ ë…¸ë“œ"""
        logger.info(f"[WEB_SEARCH] Node started")
        
        if not self.tavily_tool:
            logger.warning(f"[WEB_SEARCH] Tavily tool not available")
            return {"warnings": ["Web search unavailable"]}
        
        try:
            # í˜„ì¬ ì¿¼ë¦¬ ê°€ì ¸ì˜¤ê¸°
            query = state.get("query", "")
            logger.debug(f"[WEB_SEARCH] Original query: '{query}'")
            
            # ì„œë¸ŒíƒœìŠ¤í¬ê°€ ìˆìœ¼ë©´ í˜„ì¬ ì„œë¸ŒíƒœìŠ¤í¬ ì¿¼ë¦¬ ì‚¬ìš©
            subtasks = state.get("subtasks", [])
            current_idx = state.get("current_subtask_idx", 0)
            logger.debug(f"[WEB_SEARCH] Subtasks: {len(subtasks)}, current_idx: {current_idx}")
            
            if subtasks and current_idx < len(subtasks):
                subtask_query = subtasks[current_idx].get("query", query)
                logger.info(f"[WEB_SEARCH] Using subtask query: '{subtask_query}'")
                query = subtask_query
            
            # ì›¹ ê²€ìƒ‰ ì‹¤í–‰
            logger.info(f"[WEB_SEARCH] Executing search for: '{query}'")
            web_documents = await self.tavily_tool.search(query)
            logger.info(f"[WEB_SEARCH] Retrieved {len(web_documents)} web documents")
            
            # ê¸°ì¡´ ë¬¸ì„œì™€ ë³‘í•©
            existing_docs = state.get("documents", [])
            all_documents = existing_docs + web_documents
            logger.debug(f"[WEB_SEARCH] Total documents: {len(existing_docs)} + {len(web_documents)} = {len(all_documents)}")
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            metadata = state.get("metadata", {})
            metadata["web_search_performed"] = True
            metadata["web_search_results"] = len(web_documents)
            logger.debug(f"[WEB_SEARCH] Updated metadata")
            
            # ë©”ì‹œì§€ ìƒì„± - ì›¹ ê²€ìƒ‰ ê³¼ì • ìƒì„¸ ì •ë³´
            messages = []
            
            # 1. ì›¹ ê²€ìƒ‰ ì‹œì‘
            messages.append(
                AIMessage(content=f"ğŸŒ ì›¹ ê²€ìƒ‰ ì‹œì‘: '{query[:100]}...'")
            )
            
            # 2. ê²€ìƒ‰ ì§„í–‰
            messages.append(
                AIMessage(content="ğŸ” Tavily APIë¡œ ìµœì‹  ì •ë³´ ê²€ìƒ‰ ì¤‘...")
            )
            
            # 3. ê²€ìƒ‰ ê²°ê³¼
            if len(web_documents) > 0:
                messages.append(
                    AIMessage(content=f"ğŸ“„ {len(web_documents)}ê°œ ì›¹ ë¬¸ì„œ ë°œê²¬")
                )
                messages.append(
                    AIMessage(content=f"âœ… ì´ {len(all_documents)}ê°œ ë¬¸ì„œë¡œ ë³´ê°• ì™„ë£Œ (ê¸°ì¡´ {len(existing_docs)}ê°œ + ì›¹ {len(web_documents)}ê°œ)")
                )
            else:
                messages.append(
                    AIMessage(content="âš ï¸ ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                )
            
            result = {
                "messages": messages,  # ë©”ì‹œì§€ ì¶”ê°€
                "documents": all_documents,
                "metadata": metadata
            }
            
            # Clear error state if we found documents
            if len(web_documents) > 0:
                result["error"] = None  # Clear any previous errors
                result["workflow_status"] = "continuing"
                # ì¶”ê°€: stateì—ì„œë„ error ì œê±° (ì™„ì „í•œ error í´ë¦¬ì–´)
                if "error" in state:
                    logger.info(f"[WEB_SEARCH] Removing error from state after successful web search")
                    # stateì—ì„œ errorë¥¼ ì œê±°í•˜ëŠ” ê²ƒì€ resultë¥¼ í†µí•´ ì²˜ë¦¬
                    # LangGraphëŠ” stateë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•Šê³  return valueë¡œ ì—…ë°ì´íŠ¸
                result["errors"] = []  # errors ë¦¬ìŠ¤íŠ¸ë„ ì´ˆê¸°í™”
                result["warnings"] = []  # warningsë„ ì´ˆê¸°í™” (í•„ìš”ì‹œ)
                logger.info(f"[WEB_SEARCH] Cleared all error states after finding {len(web_documents)} documents")
            
            logger.info(f"[WEB_SEARCH] Node completed successfully")
            return result
            
        except Exception as e:
            logger.error(f"[WEB_SEARCH] Search failed: {str(e)}")
            return {
                "warnings": [f"Web search failed: {str(e)}"]
            }
    
    def _web_search_node_sync(self, state: MVPWorkflowState) -> Dict[str, Any]:
        """ì›¹ ê²€ìƒ‰ ë…¸ë“œ (ë™ê¸°)"""
        import asyncio
        from concurrent.futures import ThreadPoolExecutor
        
        try:
            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
            loop = asyncio.get_running_loop()
        except RuntimeError:
            # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•˜ì—¬ ì‹¤í–‰
            return asyncio.run(self._web_search_node(state))
        else:
            # ì´ë¯¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì´ë©´ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            with ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(asyncio.run, self._web_search_node(state))
                return future.result()
    
    async def arun(
        self, 
        query: str,
        config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ë¹„ë™ê¸° ì‹¤í–‰
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            config: ì‹¤í–‰ ì„¤ì •
            
        Returns:
            ìµœì¢… ìƒíƒœ
        """
        initial_state = {
            "query": query,
            "workflow_status": "started",
            "metadata": {},
            "retry_count": 0,
            "documents": [],
            "execution_time": {},
            "current_subtask_idx": 0,
            "subtasks": []
        }
        
        # ê·¸ë˜í”„ ì‹¤í–‰ with error handling
        try:
            async for event in self.app.astream(initial_state, config=config):
                pass  # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (í•„ìš”ì‹œ)
            
            # ìµœì¢… ìƒíƒœ ë°˜í™˜
            return event
        except GraphRecursionError as e:
            print(f"âš ï¸  ì›Œí¬í”Œë¡œìš°ê°€ recursion limitì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤: {str(e)}")
            # ë¶€ë¶„ ê²°ê³¼ ë°˜í™˜
            return {
                "error": "Recursion limit exceeded", 
                "query": query,
                "workflow_status": "failed",
                "partial_results": initial_state.get("subtask_results", [])
            }
    
    def run(
        self, 
        query: str,
        config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ë™ê¸° ì‹¤í–‰
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            config: ì‹¤í–‰ ì„¤ì •
            
        Returns:
            ìµœì¢… ìƒíƒœ
        """
        initial_state = {
            "query": query,
            "workflow_status": "started",
            "metadata": {},
            "retry_count": 0,
            "documents": [],
            "execution_time": {},
            "current_subtask_idx": 0,
            "subtasks": []
        }
        
        # ê·¸ë˜í”„ ì‹¤í–‰ with error handling
        try:
            final_state = self.app.invoke(initial_state, config=config)
            return final_state
        except GraphRecursionError as e:
            print(f"âš ï¸  ì›Œí¬í”Œë¡œìš°ê°€ recursion limitì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤: {str(e)}")
            # ë¶€ë¶„ ê²°ê³¼ ë°˜í™˜
            return {
                "error": "Recursion limit exceeded",
                "query": query,
                "workflow_status": "failed",
                "partial_results": initial_state.get("subtask_results", [])
            }
    
    def stream(
        self,
        query: str,
        config: Optional[Dict[str, Any]] = None
    ):
        """
        ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            config: ì‹¤í–‰ ì„¤ì •
            
        Yields:
            ì¤‘ê°„ ìƒíƒœë“¤
        """
        initial_state = {
            "query": query,
            "workflow_status": "started",
            "metadata": {},
            "retry_count": 0,
            "documents": [],
            "execution_time": {},
            "current_subtask_idx": 0,
            "subtasks": []
        }
        
        # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê·¸ë˜í”„ ì‹¤í–‰
        for event in self.app.stream(initial_state, config=config):
            yield event
    
    def get_graph_image(self, output_path: str = "workflow_graph.png"):
        """
        ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ì‹œê°í™”
        
        Args:
            output_path: ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ
        """
        try:
            from IPython.display import Image, display
            img = self.app.get_graph().draw_mermaid_png()
            
            # íŒŒì¼ë¡œ ì €ì¥
            with open(output_path, "wb") as f:
                f.write(img)
            
            print(f"Graph image saved to {output_path}")
            
            # Jupyter í™˜ê²½ì´ë©´ í‘œì‹œ
            try:
                display(Image(img))
            except:
                pass
                
        except ImportError:
            print("Graph visualization requires IPython")
        except Exception as e:
            print(f"Failed to generate graph image: {e}")


# í—¬í¼ í•¨ìˆ˜
def create_workflow(checkpointer_path: Optional[str] = None) -> MVPWorkflowGraph:
    """
    ì›Œí¬í”Œë¡œìš° ìƒì„± í—¬í¼ í•¨ìˆ˜
    
    Args:
        checkpointer_path: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ
        
    Returns:
        MVPWorkflowGraph ì¸ìŠ¤í„´ìŠ¤
    """
    return MVPWorkflowGraph(checkpointer_path)