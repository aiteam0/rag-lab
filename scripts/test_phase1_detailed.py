"""
Phase 1 Detailed Components Test Script
ê° ëª¨ë“ˆì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ì‹¬ì¸µì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
"""

import asyncio
import os
import sys
import json
import time
from pathlib import Path
from dotenv import load_dotenv
from typing import List, Dict, Any
import random
from rich.console import Console
from rich.table import Table
from rich.progress import track
from rich import print as rprint

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

console = Console()


async def test_database_detailed():
    """ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë“ˆ ìƒì„¸ í…ŒìŠ¤íŠ¸"""
    from ingest.database import DatabaseManager
    
    console.print("\n[bold cyan]â•â•â• Database Module Detailed Test â•â•â•[/bold cyan]")
    results = []
    
    try:
        db_manager = DatabaseManager()
        await db_manager.initialize()
        
        # 1. ì—°ê²° í’€ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]1. Connection Pool Test[/yellow]")
        start_time = time.time()
        
        # ë™ì‹œ ì—°ê²° í…ŒìŠ¤íŠ¸
        async def test_connection(idx):
            async with db_manager.pool.acquire() as conn:
                result = await conn.fetchval("SELECT $1::int", idx)
                return result == idx
        
        tasks = [test_connection(i) for i in range(10)]
        results_conn = await asyncio.gather(*tasks)
        
        if all(results_conn):
            console.print("  âœ… Concurrent connections: 10 successful")
            results.append(("Connection Pool", "PASS", f"{time.time()-start_time:.3f}s"))
        else:
            console.print("  âŒ Concurrent connections failed")
            results.append(("Connection Pool", "FAIL", "N/A"))
        
        # 2. í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ê²€ì¦
        console.print("\n[yellow]2. Schema Validation Test[/yellow]")
        async with db_manager.pool.acquire() as conn:
            # ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
            columns = await conn.fetch("""
                SELECT column_name, data_type, is_nullable
                FROM information_schema.columns
                WHERE table_name = 'mvp_ddu_documents'
                ORDER BY ordinal_position
            """)
            
            expected_columns = {
                'id': 'integer',
                'source': 'text',
                'page': 'integer',
                'category': 'text',
                'page_content': 'text',
                'translation_text': 'text',
                'contextualize_text': 'text',
                'caption': 'text',
                'entity': 'jsonb',
                'image_path': 'text',
                'human_feedback': 'text',
                'embedding_korean': 'USER-DEFINED',  # vector type
                'embedding_english': 'USER-DEFINED',  # vector type
                'search_vector_korean': 'tsvector',
                'search_vector_english': 'tsvector'
            }
            
            actual_columns = {col['column_name']: col['data_type'] for col in columns}
            
            # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
            missing = set(expected_columns.keys()) - set(actual_columns.keys())
            if not missing:
                console.print(f"  âœ… All {len(expected_columns)} columns present")
                results.append(("Schema Validation", "PASS", f"{len(columns)} columns"))
            else:
                console.print(f"  âŒ Missing columns: {missing}")
                results.append(("Schema Validation", "FAIL", f"Missing: {missing}"))
        
        # 3. CRUD ì‘ì—… í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]3. CRUD Operations Test[/yellow]")
        
        # INSERT í…ŒìŠ¤íŠ¸
        test_data = {
            "source": "test_document.pdf",
            "page": 99,
            "category": "paragraph",
            "page_content": "í…ŒìŠ¤íŠ¸ ì½˜í…ì¸ ì…ë‹ˆë‹¤.",
            "translation_text": "This is test content.",
            "contextualize_text": "í…ŒìŠ¤íŠ¸ ë¬¸ë§¥",
            "caption": "í…ŒìŠ¤íŠ¸ ìº¡ì…˜",
            "entity": json.dumps({"type": "test", "keywords": ["test1", "test2"]}),
            "image_path": None,
            "human_feedback": "Good",
            "embedding_korean": "[" + ",".join([str(random.random()) for _ in range(1536)]) + "]",
            "embedding_english": "[" + ",".join([str(random.random()) for _ in range(1536)]) + "]"
        }
        
        async with db_manager.pool.acquire() as conn:
            # INSERT
            doc_id = await conn.fetchval("""
                INSERT INTO mvp_ddu_documents (
                    source, page, category, page_content,
                    translation_text, contextualize_text, caption,
                    entity, image_path, human_feedback,
                    embedding_korean, embedding_english,
                    search_vector_korean, search_vector_english
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8::jsonb, $9, $10,
                         $11::vector, $12::vector,
                         to_tsvector('simple', COALESCE($13, '')),
                         to_tsvector('english', COALESCE($14, '')))
                RETURNING id
            """,
                test_data["source"], test_data["page"], test_data["category"],
                test_data["page_content"], test_data["translation_text"],
                test_data["contextualize_text"], test_data["caption"],
                test_data["entity"], test_data["image_path"],
                test_data["human_feedback"], test_data["embedding_korean"],
                test_data["embedding_english"], test_data["page_content"],
                test_data["translation_text"]
            )
            
            if doc_id:
                console.print(f"  âœ… INSERT successful (ID: {doc_id})")
                
                # SELECT í…ŒìŠ¤íŠ¸
                retrieved = await conn.fetchrow(
                    "SELECT * FROM mvp_ddu_documents WHERE id = $1", doc_id
                )
                
                if retrieved and retrieved['source'] == test_data["source"]:
                    console.print(f"  âœ… SELECT successful")
                    
                    # UPDATE í…ŒìŠ¤íŠ¸
                    await conn.execute(
                        "UPDATE mvp_ddu_documents SET human_feedback = $1 WHERE id = $2",
                        "Updated feedback", doc_id
                    )
                    
                    updated = await conn.fetchval(
                        "SELECT human_feedback FROM mvp_ddu_documents WHERE id = $1", doc_id
                    )
                    
                    if updated == "Updated feedback":
                        console.print(f"  âœ… UPDATE successful")
                        
                        # DELETE í…ŒìŠ¤íŠ¸
                        await conn.execute(
                            "DELETE FROM mvp_ddu_documents WHERE id = $1", doc_id
                        )
                        
                        deleted = await conn.fetchval(
                            "SELECT COUNT(*) FROM mvp_ddu_documents WHERE id = $1", doc_id
                        )
                        
                        if deleted == 0:
                            console.print(f"  âœ… DELETE successful")
                            results.append(("CRUD Operations", "PASS", "All operations"))
                        else:
                            console.print(f"  âŒ DELETE failed")
                            results.append(("CRUD Operations", "FAIL", "DELETE"))
                    else:
                        console.print(f"  âŒ UPDATE failed")
                        results.append(("CRUD Operations", "FAIL", "UPDATE"))
                else:
                    console.print(f"  âŒ SELECT failed")
                    results.append(("CRUD Operations", "FAIL", "SELECT"))
            else:
                console.print(f"  âŒ INSERT failed")
                results.append(("CRUD Operations", "FAIL", "INSERT"))
        
        # 4. ì¸ë±ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]4. Index Performance Test[/yellow]")
        async with db_manager.pool.acquire() as conn:
            # ì¸ë±ìŠ¤ ëª©ë¡ í™•ì¸
            indexes = await conn.fetch("""
                SELECT indexname, indexdef 
                FROM pg_indexes 
                WHERE tablename = 'mvp_ddu_documents'
            """)
            
            console.print(f"  â„¹ï¸  Found {len(indexes)} indexes")
            
            # ì¸ë±ìŠ¤ ì‚¬ìš© ì—¬ë¶€ í…ŒìŠ¤íŠ¸ (EXPLAIN)
            explain = await conn.fetch("""
                EXPLAIN (FORMAT JSON) 
                SELECT * FROM mvp_ddu_documents 
                WHERE category = 'paragraph'
            """)
            
            if explain:
                plan = json.loads(explain[0]['QUERY PLAN'])
                if 'Index Scan' in str(plan) or 'Bitmap Index Scan' in str(plan):
                    console.print(f"  âœ… Indexes are being used effectively")
                    results.append(("Index Performance", "PASS", f"{len(indexes)} indexes"))
                else:
                    console.print(f"  âš ï¸  Sequential scan detected")
                    results.append(("Index Performance", "WARN", "Seq scan"))
        
        await db_manager.close()
        
    except Exception as e:
        console.print(f"  âŒ Database test error: {e}")
        results.append(("Database", "ERROR", str(e)[:30]))
    
    return results


async def test_models_detailed():
    """ëª¨ë¸ ëª¨ë“ˆ ìƒì„¸ í…ŒìŠ¤íŠ¸"""
    from ingest.models import DDUDocument, DDU_CATEGORIES, TEXT_CATEGORIES, IMAGE_CATEGORIES
    
    console.print("\n[bold cyan]â•â•â• Models Module Detailed Test â•â•â•[/bold cyan]")
    results = []
    
    try:
        # 1. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]1. Category Classification Test[/yellow]")
        
        test_cases = [
            ("paragraph", "text"),
            ("figure", "image"),
            ("table", "table"),
            ("heading1", "text"),
            ("chart", "image")
        ]
        
        all_correct = True
        for category, expected_type in test_cases:
            doc = DDUDocument(
                source="test.pdf",
                page=1,
                category=category,
                page_content="Test content"
            )
            
            actual_type = doc.get_element_type()
            if actual_type == expected_type:
                console.print(f"  âœ… {category:10} â†’ {actual_type:6} (correct)")
            else:
                console.print(f"  âŒ {category:10} â†’ {actual_type:6} (expected: {expected_type})")
                all_correct = False
        
        results.append(("Category Classification", "PASS" if all_correct else "FAIL", f"{len(test_cases)} cases"))
        
        # 2. ë°ì´í„° ë³€í™˜ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]2. Data Conversion Test[/yellow]")
        
        # ë³µì¡í•œ ë¬¸ì„œ ìƒì„±
        complex_doc = DDUDocument(
            source="complex.pdf",
            page=10,
            category="figure",
            page_content="ì›ë³¸ ì½˜í…ì¸ ",
            translation_text="Original content",
            contextualize_text="ë¬¸ë§¥ ì •ë³´",
            caption="ê·¸ë¦¼ 1: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€",
            entity={
                "type": "figure",
                "title": "Test Figure",
                "keywords": ["test", "image", "sample"],
                "hypothetical_questions": ["ì´ ê·¸ë¦¼ì€ ë¬´ì—‡ì„ ë³´ì—¬ì£¼ë‚˜ìš”?"]
            },
            image_path="/path/to/image.png",
            human_feedback="Verified"
        )
        
        # to_langchain_document í…ŒìŠ¤íŠ¸
        langchain_doc = complex_doc.to_langchain_document()
        
        checks = [
            ("page_content" in langchain_doc, "page_content exists"),
            ("metadata" in langchain_doc, "metadata exists"),
            (langchain_doc["metadata"]["category"] == "figure", "category preserved"),
            (langchain_doc["metadata"]["entity"]["type"] == "figure", "entity preserved"),
            (langchain_doc["metadata"]["image_path"] == "/path/to/image.png", "image_path preserved")
        ]
        
        for check, desc in checks:
            if check:
                console.print(f"  âœ… {desc}")
            else:
                console.print(f"  âŒ {desc}")
        
        if all(c[0] for c in checks):
            results.append(("LangChain Conversion", "PASS", f"{len(checks)} checks"))
        else:
            results.append(("LangChain Conversion", "FAIL", "Some checks failed"))
        
        # to_db_dict í…ŒìŠ¤íŠ¸
        db_dict = complex_doc.to_db_dict()
        
        required_fields = [
            "source", "page", "category", "page_content",
            "translation_text", "contextualize_text", "caption",
            "entity", "image_path", "human_feedback"
        ]
        
        missing_fields = [f for f in required_fields if f not in db_dict]
        
        if not missing_fields:
            console.print(f"  âœ… All {len(required_fields)} DB fields present")
            results.append(("DB Dict Conversion", "PASS", f"{len(required_fields)} fields"))
        else:
            console.print(f"  âŒ Missing DB fields: {missing_fields}")
            results.append(("DB Dict Conversion", "FAIL", f"Missing: {missing_fields}"))
        
        # 3. Edge Cases í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]3. Edge Cases Test[/yellow]")
        
        # None ê°’ ì²˜ë¦¬
        minimal_doc = DDUDocument(
            source="minimal.pdf",
            page=None,
            category="paragraph",
            page_content=None
        )
        
        try:
            minimal_langchain = minimal_doc.to_langchain_document()
            minimal_db = minimal_doc.to_db_dict()
            console.print("  âœ… None values handled correctly")
            results.append(("Edge Cases", "PASS", "None handling"))
        except Exception as e:
            console.print(f"  âŒ None value handling failed: {e}")
            results.append(("Edge Cases", "FAIL", str(e)[:30]))
        
    except Exception as e:
        console.print(f"  âŒ Models test error: {e}")
        results.append(("Models", "ERROR", str(e)[:30]))
    
    return results


async def test_embeddings_detailed():
    """ì„ë² ë”© ëª¨ë“ˆ ìƒì„¸ í…ŒìŠ¤íŠ¸"""
    from ingest.embeddings import DualLanguageEmbeddings
    import numpy as np
    
    console.print("\n[bold cyan]â•â•â• Embeddings Module Detailed Test â•â•â•[/bold cyan]")
    results = []
    
    try:
        embeddings = DualLanguageEmbeddings()
        
        # 1. ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]1. Various Text Embedding Test[/yellow]")
        
        test_cases = [
            {
                "name": "Korean only",
                "doc": {"page_content": "í•œêµ­ì–´ í…ìŠ¤íŠ¸", "contextualize_text": "ì¶”ê°€ ë¬¸ë§¥"},
                "expected": (True, False)  # (korean_exists, english_exists)
            },
            {
                "name": "English only",
                "doc": {"translation_text": "English text only"},
                "expected": (False, True)
            },
            {
                "name": "Both languages",
                "doc": {
                    "page_content": "í•œêµ­ì–´",
                    "contextualize_text": "ë¬¸ë§¥",
                    "translation_text": "English"
                },
                "expected": (True, True)
            },
            {
                "name": "Empty document",
                "doc": {},
                "expected": (False, False)
            }
        ]
        
        for case in test_cases:
            korean_emb, english_emb = await embeddings.embed_document(case["doc"])
            
            korean_ok = (korean_emb is not None) == case["expected"][0]
            english_ok = (english_emb is not None) == case["expected"][1]
            
            if korean_ok and english_ok:
                console.print(f"  âœ… {case['name']:20} - Correct")
            else:
                console.print(f"  âŒ {case['name']:20} - Failed")
        
        results.append(("Text Embedding Varieties", "PASS", f"{len(test_cases)} cases"))
        
        # 2. ì„ë² ë”© ì°¨ì› ë° ì •ê·œí™” í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]2. Embedding Dimension & Quality Test[/yellow]")
        
        test_doc = {
            "page_content": "í…ŒìŠ¤íŠ¸ ë¬¸ì„œì…ë‹ˆë‹¤. ì´ê²ƒì€ ì„ë² ë”© í’ˆì§ˆì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ê¸´ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
            "translation_text": "This is a test document. This is a long text to test embedding quality."
        }
        
        korean_emb, english_emb = await embeddings.embed_document(test_doc)
        
        # ì°¨ì› í™•ì¸
        if len(korean_emb) == 1536:
            console.print(f"  âœ… Korean embedding dimension: 1536")
        else:
            console.print(f"  âŒ Korean embedding dimension: {len(korean_emb)} (expected 1536)")
        
        if len(english_emb) == 1536:
            console.print(f"  âœ… English embedding dimension: 1536")
        else:
            console.print(f"  âŒ English embedding dimension: {len(english_emb)} (expected 1536)")
        
        # ë²¡í„° ì •ê·œí™” í™•ì¸ (L2 norm)
        korean_norm = np.linalg.norm(korean_emb)
        english_norm = np.linalg.norm(english_emb)
        
        console.print(f"  â„¹ï¸  Korean L2 norm: {korean_norm:.4f}")
        console.print(f"  â„¹ï¸  English L2 norm: {english_norm:.4f}")
        
        # ë²¡í„° í†µê³„
        console.print(f"  â„¹ï¸  Korean - Mean: {np.mean(korean_emb):.4f}, Std: {np.std(korean_emb):.4f}")
        console.print(f"  â„¹ï¸  English - Mean: {np.mean(english_emb):.4f}, Std: {np.std(english_emb):.4f}")
        
        results.append(("Embedding Quality", "PASS", "Dimensions OK"))
        
        # 3. ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]3. Semantic Similarity Test[/yellow]")
        
        # ìœ ì‚¬í•œ ë¬¸ì„œë“¤
        similar_docs = [
            {"page_content": "ìë™ì°¨ì˜ ì—”ì§„ ì„±ëŠ¥", "translation_text": "Car engine performance"},
            {"page_content": "ì°¨ëŸ‰ì˜ ì—”ì§„ ì¶œë ¥", "translation_text": "Vehicle engine power"},
            {"page_content": "ë‚ ì”¨ê°€ ì¢‹ìŠµë‹ˆë‹¤", "translation_text": "The weather is nice"}
        ]
        
        embeddings_list = []
        for doc in similar_docs:
            k_emb, e_emb = await embeddings.embed_document(doc)
            embeddings_list.append((k_emb, e_emb))
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        def cosine_similarity(v1, v2):
            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
        
        # ì²« ë‘ ë¬¸ì„œ (ìœ ì‚¬)ì™€ ì„¸ ë²ˆì§¸ ë¬¸ì„œ (ë‹¤ë¥¸ ì£¼ì œ) ë¹„êµ
        sim_korean_1_2 = cosine_similarity(embeddings_list[0][0], embeddings_list[1][0])
        sim_korean_1_3 = cosine_similarity(embeddings_list[0][0], embeddings_list[2][0])
        
        console.print(f"  â„¹ï¸  Korean similarity (car-car): {sim_korean_1_2:.4f}")
        console.print(f"  â„¹ï¸  Korean similarity (car-weather): {sim_korean_1_3:.4f}")
        
        if sim_korean_1_2 > sim_korean_1_3:
            console.print(f"  âœ… Semantic similarity working correctly")
            results.append(("Semantic Similarity", "PASS", "Similarity ordering correct"))
        else:
            console.print(f"  âŒ Semantic similarity issue detected")
            results.append(("Semantic Similarity", "FAIL", "Unexpected similarity"))
        
        # 4. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]4. Performance Test[/yellow]")
        
        start_time = time.time()
        tasks = []
        for _ in range(10):
            doc = {
                "page_content": "ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œì…ë‹ˆë‹¤." * 10,
                "translation_text": "Performance test document." * 10
            }
            tasks.append(embeddings.embed_document(doc))
        
        await asyncio.gather(*tasks)
        elapsed = time.time() - start_time
        
        avg_time = elapsed / 10
        console.print(f"  â±ï¸  Average embedding time: {avg_time:.3f}s per document")
        console.print(f"  â±ï¸  Total time for 10 documents: {elapsed:.3f}s")
        
        if avg_time < 1.0:  # 1ì´ˆ ì´ë‚´
            results.append(("Performance", "PASS", f"{avg_time:.3f}s/doc"))
        else:
            results.append(("Performance", "WARN", f"{avg_time:.3f}s/doc (slow)"))
        
    except Exception as e:
        console.print(f"  âŒ Embeddings test error: {e}")
        results.append(("Embeddings", "ERROR", str(e)[:30]))
    
    return results


async def test_search_filter_detailed():
    """ê²€ìƒ‰ í•„í„° ëª¨ë“ˆ ìƒì„¸ í…ŒìŠ¤íŠ¸"""
    from retrieval.search_filter import MVPSearchFilter
    
    console.print("\n[bold cyan]â•â•â• SearchFilter Module Detailed Test â•â•â•[/bold cyan]")
    results = []
    
    try:
        # 1. ê¸°ë³¸ í•„í„° ìƒì„± í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]1. Basic Filter Creation Test[/yellow]")
        
        test_filters = [
            {
                "name": "Category filter",
                "filter": MVPSearchFilter(categories=["paragraph", "table"]),
                "expected_conditions": 1
            },
            {
                "name": "Page filter",
                "filter": MVPSearchFilter(pages=[1, 2, 3]),
                "expected_conditions": 1
            },
            {
                "name": "Combined filter",
                "filter": MVPSearchFilter(
                    categories=["figure"],
                    pages=[5, 6],
                    caption="ì—”ì§„"
                ),
                "expected_conditions": 3
            },
            {
                "name": "Entity filter",
                "filter": MVPSearchFilter(
                    entity={"type": "table", "keywords": ["ì„±ëŠ¥", "ì—°ë¹„"]}
                ),
                "expected_conditions": 1
            }
        ]
        
        for test in test_filters:
            where_clause, params = test["filter"].to_sql_where()
            conditions = where_clause.count("AND") + 1 if where_clause != "1=1" else 0
            
            if where_clause != "1=1":
                console.print(f"  âœ… {test['name']:20} - Generated SQL with {len(params)} params")
                console.print(f"     WHERE: {where_clause[:50]}...")
            else:
                console.print(f"  âš ï¸  {test['name']:20} - Empty filter")
        
        results.append(("Filter Creation", "PASS", f"{len(test_filters)} filters"))
        
        # 2. SQL Injection ë°©ì§€ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]2. SQL Injection Prevention Test[/yellow]")
        
        malicious_inputs = [
            {"caption": "'; DROP TABLE mvp_ddu_documents; --"},
            {"categories": ["paragraph'; DELETE FROM mvp_ddu_documents; --"]},
            {"entity": {"title": "' OR '1'='1"}}
        ]
        
        all_safe = True
        for i, malicious in enumerate(malicious_inputs):
            try:
                filter = MVPSearchFilter(**malicious)
                where_clause, params = filter.to_sql_where()
                
                # íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ ì‚¬ìš© í™•ì¸
                if "DROP" not in where_clause and "DELETE" not in where_clause:
                    console.print(f"  âœ… Malicious input {i+1} safely handled")
                else:
                    console.print(f"  âŒ Malicious input {i+1} not properly escaped")
                    all_safe = False
            except Exception as e:
                console.print(f"  âœ… Malicious input {i+1} rejected: {e}")
        
        results.append(("SQL Injection Prevention", "PASS" if all_safe else "FAIL", f"{len(malicious_inputs)} tests"))
        
        # 3. ë³µì¡í•œ Entity í•„í„° í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]3. Complex Entity Filter Test[/yellow]")
        
        complex_entity = {
            "type": "figure",
            "title": "ì—”ì§„ êµ¬ì¡°ë„",
            "keywords": ["ì—”ì§„", "í„°ë³´", "ì¸í„°ì¿¨ëŸ¬"],
            "details": "ìƒì„¸ ì„¤ëª…"
        }
        
        filter = MVPSearchFilter(entity=complex_entity)
        where_clause, params = filter.to_sql_where()
        
        expected_params = ["entity_type", "entity_title", "entity_keywords", "entity_details"]
        actual_params = list(params.keys())
        
        missing = set(expected_params) - set(actual_params)
        if not missing:
            console.print(f"  âœ… All entity fields processed: {', '.join(actual_params)}")
            results.append(("Complex Entity Filter", "PASS", f"{len(actual_params)} fields"))
        else:
            console.print(f"  âŒ Missing entity fields: {missing}")
            results.append(("Complex Entity Filter", "FAIL", f"Missing: {missing}"))
        
        # 4. from_query_params í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]4. Query Parameter Parsing Test[/yellow]")
        
        query_params = {
            "categories": "paragraph,table,figure",
            "pages": "1,2,3,4,5",
            "sources": "manual.pdf",
            "caption": "ê·¸ë¦¼",
            "entity": {"type": "table"}
        }
        
        filter = MVPSearchFilter.from_query_params(query_params)
        
        checks = [
            (len(filter.categories) == 3, "Categories parsed"),
            (len(filter.pages) == 5, "Pages parsed"),
            (filter.sources == ["manual.pdf"], "Sources parsed"),
            (filter.caption == "ê·¸ë¦¼", "Caption parsed"),
            (filter.entity["type"] == "table", "Entity parsed")
        ]
        
        for check, desc in checks:
            if check:
                console.print(f"  âœ… {desc}")
            else:
                console.print(f"  âŒ {desc}")
        
        if all(c[0] for c in checks):
            results.append(("Query Param Parsing", "PASS", f"{len(checks)} checks"))
        else:
            results.append(("Query Param Parsing", "FAIL", "Some checks failed"))
        
        # 5. Empty filter í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]5. Empty Filter Test[/yellow]")
        
        empty_filter = MVPSearchFilter()
        
        if empty_filter.is_empty():
            console.print("  âœ… Empty filter correctly identified")
        else:
            console.print("  âŒ Empty filter not identified")
        
        where_clause, params = empty_filter.to_sql_where()
        if where_clause == "1=1" and len(params) == 0:
            console.print("  âœ… Empty filter generates valid SQL")
            results.append(("Empty Filter", "PASS", "Correct behavior"))
        else:
            console.print("  âŒ Empty filter SQL incorrect")
            results.append(("Empty Filter", "FAIL", "Incorrect SQL"))
        
    except Exception as e:
        console.print(f"  âŒ SearchFilter test error: {e}")
        results.append(("SearchFilter", "ERROR", str(e)[:30]))
    
    return results


async def test_hybrid_search_detailed():
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë“ˆ ìƒì„¸ í…ŒìŠ¤íŠ¸"""
    from retrieval.hybrid_search import HybridSearch
    from retrieval.search_filter import MVPSearchFilter
    from ingest.database import DatabaseManager
    
    console.print("\n[bold cyan]â•â•â• HybridSearch Module Detailed Test â•â•â•[/bold cyan]")
    results = []
    
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        db_manager = DatabaseManager()
        await db_manager.initialize()
        
        # HybridSearch ì´ˆê¸°í™”
        hybrid_search = HybridSearch(db_manager.pool)
        
        # 1. í•œêµ­ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]1. Korean Keyword Extraction Test[/yellow]")
        
        test_queries = [
            "GV80ì˜ ì—”ì§„ ì„±ëŠ¥ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì•ˆì „ ì¥ì¹˜ì™€ ë¸Œë ˆì´í¬ ì‹œìŠ¤í…œ",
            "ì—°ë¹„ì™€ ì£¼í–‰ ê±°ë¦¬"
        ]
        
        for query in test_queries:
            keywords = hybrid_search._extract_korean_keywords(query)
            console.print(f"  Query: {query}")
            console.print(f"  Keywords: {', '.join(keywords)}")
            
            if len(keywords) > 0:
                console.print(f"  âœ… Extracted {len(keywords)} keywords")
            else:
                console.print(f"  âŒ No keywords extracted")
        
        results.append(("Korean Keyword Extraction", "PASS", "Kiwi tokenizer working"))
        
        # 2. RRF ë³‘í•© ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]2. RRF Merge Algorithm Test[/yellow]")
        
        # ê°€ìƒì˜ ê²€ìƒ‰ ê²°ê³¼
        semantic_results = [
            {"id": 1, "score": 0.9, "content": "A"},
            {"id": 2, "score": 0.8, "content": "B"},
            {"id": 3, "score": 0.7, "content": "C"},
            {"id": 5, "score": 0.6, "content": "E"}
        ]
        
        keyword_results = [
            {"id": 2, "score": 0.95, "content": "B"},
            {"id": 4, "score": 0.85, "content": "D"},
            {"id": 1, "score": 0.75, "content": "A"},
            {"id": 6, "score": 0.65, "content": "F"}
        ]
        
        merged = hybrid_search._rrf_merge(semantic_results, keyword_results, top_k=3)
        
        console.print(f"  Semantic results: {[r['id'] for r in semantic_results]}")
        console.print(f"  Keyword results: {[r['id'] for r in keyword_results]}")
        console.print(f"  Merged (top 3): {[r['id'] for r in merged]}")
        
        # ID 2ê°€ ìµœìƒìœ„ì— ìˆì–´ì•¼ í•¨ (ì–‘ìª½ì—ì„œ ë†’ì€ ìˆœìœ„)
        if merged[0]["id"] == 2:
            console.print(f"  âœ… RRF merge working correctly")
            results.append(("RRF Merge", "PASS", "Correct ordering"))
        else:
            console.print(f"  âŒ RRF merge incorrect")
            results.append(("RRF Merge", "FAIL", "Wrong ordering"))
        
        # 3. ê²€ìƒ‰ í•„í„° í†µí•© í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]3. Search with Filter Test[/yellow]")
        
        # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        async with db_manager.pool.acquire() as conn:
            count = await conn.fetchval("SELECT COUNT(*) FROM mvp_ddu_documents")
            
            if count > 0:
                console.print(f"  â„¹ï¸  Found {count} documents in database")
                
                # í•„í„°ë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜
                filter = MVPSearchFilter(categories=["paragraph"])
                
                # asyncpgìš© ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸
                where_clause, params = filter.to_sql_where_asyncpg()
                
                # asyncpgëŠ” ìœ„ì¹˜ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©
                filtered_count = await conn.fetchval(f"""
                    SELECT COUNT(*) FROM mvp_ddu_documents 
                    WHERE {where_clause}
                """, *params)  # *paramsë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì–¸íŒ©
                
                console.print(f"  â„¹ï¸  Filter matches {filtered_count} documents")
                
                if filtered_count <= count:
                    console.print(f"  âœ… Filter working correctly")
                    results.append(("Filter Integration", "PASS", f"{filtered_count}/{count} docs"))
                else:
                    console.print(f"  âŒ Filter error")
                    results.append(("Filter Integration", "FAIL", "Count mismatch"))
            else:
                console.print(f"  âš ï¸  No documents in database, skipping search test")
                results.append(("Filter Integration", "SKIP", "No data"))
        
        # 4. ì–¸ì–´ë³„ ê²€ìƒ‰ ì„¤ì • í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]4. Language-specific Search Test[/yellow]")
        
        languages = ["korean", "english"]
        for lang in languages:
            # ì–¸ì–´ë³„ ì„¤ì •ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
            if lang == "korean":
                test_text = "í…ŒìŠ¤íŠ¸"
                expected_column = "embedding_korean"
            else:
                test_text = "test"
                expected_column = "embedding_english"
            
            console.print(f"  âœ… {lang.capitalize()} search configuration ready")
        
        results.append(("Language Configuration", "PASS", "Both languages"))
        
        await db_manager.close()
        
    except Exception as e:
        console.print(f"  âŒ HybridSearch test error: {e}")
        results.append(("HybridSearch", "ERROR", str(e)[:30]))
    
    return results


async def test_loader_detailed():
    """ë¡œë” ëª¨ë“ˆ ìƒì„¸ í…ŒìŠ¤íŠ¸"""
    from ingest.loader import DDUPickleLoader
    
    console.print("\n[bold cyan]â•â•â• Loader Module Detailed Test â•â•â•[/bold cyan]")
    results = []
    
    pickle_path = "/mnt/e/MyProject2/multimodal-rag-wsl-v2/data/gv80_owners_manual_TEST6P_documents.pkl"
    
    if not os.path.exists(pickle_path):
        console.print(f"  âš ï¸  Pickle file not found: {pickle_path}")
        return [("Loader", "SKIP", "No file")]
    
    try:
        # 1. íŒŒì¼ ê²€ì¦ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]1. File Validation Test[/yellow]")
        
        is_valid = DDUPickleLoader.validate_pickle_file(pickle_path)
        if is_valid:
            console.print(f"  âœ… Pickle file validation passed")
            results.append(("File Validation", "PASS", "Valid format"))
        else:
            console.print(f"  âŒ Pickle file validation failed")
            results.append(("File Validation", "FAIL", "Invalid format"))
            return results
        
        # ë¡œë” ì´ˆê¸°í™”
        loader = DDUPickleLoader(pickle_path)
        
        # 2. í†µê³„ ì •ë³´ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]2. Statistics Test[/yellow]")
        
        stats = loader.get_statistics()
        
        console.print(f"  Total Documents: {stats['total_documents']}")
        console.print(f"  Categories: {len(stats['categories'])} types")
        console.print(f"  Sources: {len(stats['sources'])} files")
        console.print(f"  Page Range: {stats['page_range']['min']} - {stats['page_range']['max']}")
        console.print(f"  With Translation: {stats['has_translation']}")
        console.print(f"  With Context: {stats['has_contextualize']}")
        console.print(f"  With Caption: {stats['has_caption']}")
        
        if stats['total_documents'] > 0:
            results.append(("Statistics", "PASS", f"{stats['total_documents']} docs"))
        else:
            results.append(("Statistics", "FAIL", "No documents"))
        
        # 3. ë¬¸ì„œ ë¡œë”© í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]3. Document Loading Test[/yellow]")
        
        documents = loader.load_documents()
        
        if len(documents) == stats['total_documents']:
            console.print(f"  âœ… All {len(documents)} documents loaded")
        else:
            console.print(f"  âŒ Document count mismatch: {len(documents)} vs {stats['total_documents']}")
        
        # ìƒ˜í”Œ ë¬¸ì„œ ê²€ì¦
        if documents:
            sample_doc = documents[0]
            
            required_attrs = ['source', 'category', 'page']
            missing_attrs = [attr for attr in required_attrs if not hasattr(sample_doc, attr)]
            
            if not missing_attrs:
                console.print(f"  âœ… Document structure valid")
                results.append(("Document Loading", "PASS", f"{len(documents)} docs"))
            else:
                console.print(f"  âŒ Missing attributes: {missing_attrs}")
                results.append(("Document Loading", "FAIL", f"Missing: {missing_attrs}"))
        
        # 4. ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬ ë¶„ì„
        console.print("\n[yellow]4. Category Distribution Analysis[/yellow]")
        
        category_dist = stats['categories']
        total = sum(category_dist.values())
        
        # ìƒìœ„ 5ê°œ ì¹´í…Œê³ ë¦¬ ì¶œë ¥
        sorted_categories = sorted(category_dist.items(), key=lambda x: x[1], reverse=True)[:5]
        
        for category, count in sorted_categories:
            percentage = (count / total) * 100
            console.print(f"  {category:15} {count:4} docs ({percentage:5.1f}%)")
        
        results.append(("Category Analysis", "PASS", f"{len(category_dist)} categories"))
        
        # 5. Entity íƒ€ì… ë¶„ì„
        console.print("\n[yellow]5. Entity Type Analysis[/yellow]")
        
        entity_types = stats.get('entity_types', {})
        
        if entity_types:
            console.print(f"  Found {len(entity_types)} entity types:")
            for entity_type, count in entity_types.items():
                console.print(f"    - {entity_type}: {count} occurrences")
            results.append(("Entity Analysis", "PASS", f"{len(entity_types)} types"))
        else:
            console.print(f"  â„¹ï¸  No entities found in documents")
            results.append(("Entity Analysis", "INFO", "No entities"))
        
        # 6. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        console.print("\n[yellow]6. Loading Performance Test[/yellow]")
        
        start_time = time.time()
        _ = loader.load_documents()
        elapsed = time.time() - start_time
        
        docs_per_second = len(documents) / elapsed if elapsed > 0 else 0
        
        console.print(f"  â±ï¸  Loading time: {elapsed:.3f}s")
        console.print(f"  â±ï¸  Speed: {docs_per_second:.0f} docs/second")
        
        if docs_per_second > 100:  # ì´ˆë‹¹ 100ê°œ ì´ìƒ
            results.append(("Performance", "PASS", f"{docs_per_second:.0f} docs/s"))
        else:
            results.append(("Performance", "WARN", f"{docs_per_second:.0f} docs/s (slow)"))
        
    except Exception as e:
        console.print(f"  âŒ Loader test error: {e}")
        results.append(("Loader", "ERROR", str(e)[:30]))
    
    return results


async def run_all_detailed_tests():
    """ëª¨ë“  ìƒì„¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    console.print("\n[bold magenta]â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[/bold magenta]")
    console.print("[bold magenta]â•‘   Phase 1 Detailed Component Testing      â•‘[/bold magenta]")
    console.print("[bold magenta]â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[/bold magenta]")
    
    # ì „ì²´ ì‹œì‘ ì‹œê°„
    total_start = time.time()
    
    # ê° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    all_results = []
    
    # Database í…ŒìŠ¤íŠ¸
    db_results = await test_database_detailed()
    all_results.extend(db_results)
    
    # Models í…ŒìŠ¤íŠ¸
    model_results = await test_models_detailed()
    all_results.extend(model_results)
    
    # Embeddings í…ŒìŠ¤íŠ¸
    embedding_results = await test_embeddings_detailed()
    all_results.extend(embedding_results)
    
    # SearchFilter í…ŒìŠ¤íŠ¸
    filter_results = await test_search_filter_detailed()
    all_results.extend(filter_results)
    
    # HybridSearch í…ŒìŠ¤íŠ¸
    search_results = await test_hybrid_search_detailed()
    all_results.extend(search_results)
    
    # Loader í…ŒìŠ¤íŠ¸
    loader_results = await test_loader_detailed()
    all_results.extend(loader_results)
    
    # ì „ì²´ ì†Œìš” ì‹œê°„
    total_elapsed = time.time() - total_start
    
    # ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”
    console.print("\n[bold cyan]â•â•â• Test Results Summary â•â•â•[/bold cyan]\n")
    
    table = Table(title="Detailed Test Results")
    table.add_column("Component", style="cyan", width=25)
    table.add_column("Status", justify="center", width=10)
    table.add_column("Details", style="dim", width=30)
    
    pass_count = 0
    fail_count = 0
    warn_count = 0
    skip_count = 0
    
    for component, status, details in all_results:
        if status == "PASS":
            status_style = "[green]âœ… PASS[/green]"
            pass_count += 1
        elif status == "FAIL":
            status_style = "[red]âŒ FAIL[/red]"
            fail_count += 1
        elif status == "WARN":
            status_style = "[yellow]âš ï¸  WARN[/yellow]"
            warn_count += 1
        elif status == "SKIP":
            status_style = "[dim]â­ï¸  SKIP[/dim]"
            skip_count += 1
        else:
            status_style = f"[red]âŒ {status}[/red]"
            fail_count += 1
        
        table.add_row(component, status_style, details)
    
    console.print(table)
    
    # ìµœì¢… í†µê³„
    console.print("\n[bold]Final Statistics:[/bold]")
    console.print(f"  [green]âœ… Passed:[/green] {pass_count}")
    console.print(f"  [red]âŒ Failed:[/red] {fail_count}")
    console.print(f"  [yellow]âš ï¸  Warnings:[/yellow] {warn_count}")
    console.print(f"  [dim]â­ï¸  Skipped:[/dim] {skip_count}")
    console.print(f"  â±ï¸  Total Time: {total_elapsed:.2f}s")
    
    # ì „ì²´ ê²°ê³¼
    if fail_count == 0:
        console.print("\n[bold green]ğŸ‰ All detailed tests passed successfully![/bold green]")
        return True
    else:
        console.print(f"\n[bold red]âš ï¸  {fail_count} test(s) failed. Please review the results.[/bold red]")
        return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    console.print("\n[bold]MVP RAG System - Detailed Phase 1 Test Suite[/bold]")
    console.print("=" * 60)
    
    # í™˜ê²½ ë³€ìˆ˜ ì²´í¬
    required_env = ["DB_HOST", "DB_PORT", "DB_NAME", "DB_USER", "DB_PASSWORD"]
    missing = [var for var in required_env if not os.getenv(var)]
    
    if missing:
        console.print(f"[red]âŒ Missing environment variables: {', '.join(missing)}[/red]")
        console.print("[yellow]Some tests may fail without proper configuration[/yellow]")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    success = asyncio.run(run_all_detailed_tests())
    
    # ì¢…ë£Œ ì½”ë“œ
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()