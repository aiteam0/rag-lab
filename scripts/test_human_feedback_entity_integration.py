"""
Human Feedback & Entity Integration Test Script
Human feedbackê³¼ Entity í•„ë“œ í™œìš©ì´ ì œëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.text import Text
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from workflow.graph import create_workflow_graph

# Rich console ì´ˆê¸°í™”
console = Console()

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


async def test_entity_table_query():
    """í…Œì´ë¸” entityê°€ ìˆëŠ” ë¬¸ì„œì— ëŒ€í•œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
    console.print("\n[bold cyan]Test 1: Table Entity Query[/bold cyan]")
    console.print("Testing retrieval and synthesis of table information...")
    
    # í…Œì´ë¸” ê´€ë ¨ ì¿¼ë¦¬
    query = "GV80ì˜ ì—”ì§„ ì˜¤ì¼ êµì²´ ì£¼ê¸°ì™€ ìš©ëŸ‰ì€ ì–¼ë§ˆì¸ê°€ìš”?"
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    graph = create_workflow_graph()
    
    try:
        result = await graph.ainvoke({
            "query": query,
            "messages": []
        })
        
        # ê²°ê³¼ ë¶„ì„
        console.print("\n[bold green]âœ… Query Executed Successfully[/bold green]")
        
        # Entity ì •ë³´ê°€ í¬í•¨ëœ ë¬¸ì„œ í™•ì¸
        if result.get("documents"):
            table_docs = [
                doc for doc in result["documents"] 
                if doc.metadata.get("category") == "table" and doc.metadata.get("entity")
            ]
            
            if table_docs:
                console.print(f"[green]Found {len(table_docs)} table documents with entity info[/green]")
                for doc in table_docs[:2]:
                    entity = doc.metadata.get("entity", {})
                    console.print(f"  - Table: {entity.get('title', 'No title')}")
                    if entity.get('keywords'):
                        console.print(f"    Keywords: {', '.join(entity['keywords'][:3])}")
            else:
                console.print("[yellow]No table documents with entity found[/yellow]")
        
        # ìµœì¢… ë‹µë³€ í™•ì¸
        if result.get("final_answer"):
            console.print("\n[bold]Final Answer (first 500 chars):[/bold]")
            console.print(result["final_answer"][:500])
        
        return True
        
    except Exception as e:
        console.print(f"[red]Error: {e}[/red]")
        return False


async def test_human_feedback_priority():
    """Human feedback ìš°ì„ ìˆœìœ„ í…ŒìŠ¤íŠ¸"""
    console.print("\n[bold cyan]Test 2: Human Feedback Priority[/bold cyan]")
    console.print("Testing if human feedback takes priority over raw content...")
    
    # Human feedbackì´ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì¿¼ë¦¬
    query = "GV80 ì°¨ëŸ‰ì˜ ì •ê¸° ì ê²€ í•­ëª©ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    graph = create_workflow_graph()
    
    try:
        result = await graph.ainvoke({
            "query": query,
            "messages": []
        })
        
        console.print("\n[bold green]âœ… Query Executed Successfully[/bold green]")
        
        # Human feedbackì´ ìˆëŠ” ë¬¸ì„œ í™•ì¸
        if result.get("documents"):
            feedback_docs = [
                doc for doc in result["documents"] 
                if doc.metadata.get("human_feedback") and doc.metadata["human_feedback"].strip()
            ]
            
            if feedback_docs:
                console.print(f"[green]Found {len(feedback_docs)} documents with human feedback[/green]")
                for doc in feedback_docs[:2]:
                    feedback = doc.metadata.get("human_feedback", "")
                    console.print(f"  - Feedback: {feedback[:100]}...")
            else:
                console.print("[yellow]No documents with human feedback found[/yellow]")
                console.print("[yellow]Note: This is expected if database doesn't have human feedback yet[/yellow]")
        
        return True
        
    except Exception as e:
        console.print(f"[red]Error: {e}[/red]")
        return False


async def test_synthesis_formatting():
    """Synthesis ë…¸ë“œì˜ entity í¬ë§·íŒ… í…ŒìŠ¤íŠ¸"""
    console.print("\n[bold cyan]Test 3: Synthesis Entity Formatting[/bold cyan]")
    console.print("Testing if synthesis properly formats entity information...")
    
    # ê·¸ë¦¼ì´ë‚˜ í…Œì´ë¸”ì´ í¬í•¨ëœ ì¿¼ë¦¬
    query = "GV80ì˜ ê³„ê¸°íŒ ê²½ê³ ë“± ì¢…ë¥˜ì™€ ì˜ë¯¸ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    graph = create_workflow_graph()
    
    try:
        result = await graph.ainvoke({
            "query": query,
            "messages": []
        })
        
        console.print("\n[bold green]âœ… Query Executed Successfully[/bold green]")
        
        # Figure ë¬¸ì„œ í™•ì¸
        if result.get("documents"):
            figure_docs = [
                doc for doc in result["documents"] 
                if doc.metadata.get("category") == "figure"
            ]
            
            if figure_docs:
                console.print(f"[green]Found {len(figure_docs)} figure documents[/green]")
                for doc in figure_docs[:2]:
                    console.print(f"  - Page: {doc.metadata.get('page')}")
                    if doc.metadata.get("caption"):
                        console.print(f"    Caption: {doc.metadata['caption'][:80]}...")
            else:
                console.print("[yellow]No figure documents found[/yellow]")
        
        # Synthesis í’ˆì§ˆ í™•ì¸
        if result.get("synthesis_result"):
            synth = result["synthesis_result"]
            console.print(f"\n[bold]Synthesis Quality:[/bold]")
            console.print(f"  - Confidence: {synth.get('confidence', 0):.2f}")
            console.print(f"  - Sources Used: {len(synth.get('sources_used', []))}")
            console.print(f"  - Key Points: {len(synth.get('key_points', []))}")
        
        return True
        
    except Exception as e:
        console.print(f"[red]Error: {e}[/red]")
        return False


async def test_hallucination_check_enhancement():
    """HallucinationCheck ê°•í™” í…ŒìŠ¤íŠ¸"""
    console.print("\n[bold cyan]Test 4: Enhanced Hallucination Check[/bold cyan]")
    console.print("Testing if hallucination check uses entity and human feedback...")
    
    # êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ê°€ í•„ìš”í•œ ì¿¼ë¦¬
    query = "GV80 ì—”ì§„ì˜ ìµœëŒ€ ì¶œë ¥ê³¼ í† í¬ëŠ” ì–¼ë§ˆì…ë‹ˆê¹Œ?"
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    graph = create_workflow_graph()
    
    try:
        result = await graph.ainvoke({
            "query": query,
            "messages": []
        })
        
        console.print("\n[bold green]âœ… Query Executed Successfully[/bold green]")
        
        # í™˜ê° ì²´í¬ ê²°ê³¼ í™•ì¸
        if result.get("hallucination_check"):
            check = result["hallucination_check"]
            console.print(f"\n[bold]Hallucination Check Results:[/bold]")
            console.print(f"  - Is Valid: {check.get('is_valid', False)}")
            console.print(f"  - Score: {check.get('score', 1.0):.2f}")
            
            if check.get('reason'):
                console.print(f"  - Reason: {check['reason'][:150]}...")
            
            # ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ (í™˜ê°ì´ ì ìœ¼ë©´) ì„±ê³µ
            if check.get('score', 1.0) < 0.5:
                console.print("[green]Good! Low hallucination score indicates grounded answer[/green]")
            else:
                console.print("[yellow]High hallucination score - may need more specific documents[/yellow]")
        
        return True
        
    except Exception as e:
        console.print(f"[red]Error: {e}[/red]")
        return False


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    console.print(Panel.fit(
        "[bold magenta]Human Feedback & Entity Integration Test Suite[/bold magenta]\n"
        "Testing the integration of human feedback and entity fields",
        title="ğŸ§ª Integration Test",
        border_style="magenta"
    ))
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tests = [
        ("Entity Table Query", test_entity_table_query),
        ("Human Feedback Priority", test_human_feedback_priority),
        ("Synthesis Formatting", test_synthesis_formatting),
        ("Hallucination Check", test_hallucination_check_enhancement)
    ]
    
    results = []
    for name, test_func in tests:
        console.print(f"\n{'='*60}")
        success = await test_func()
        results.append((name, success))
        await asyncio.sleep(1)  # API rate limiting ë°©ì§€
    
    # ê²°ê³¼ ìš”ì•½
    console.print(f"\n{'='*60}")
    console.print("\n[bold cyan]Test Summary:[/bold cyan]")
    
    table = Table(title="Test Results", show_header=True, header_style="bold")
    table.add_column("Test Name", style="cyan")
    table.add_column("Result", justify="center")
    
    passed = 0
    for name, success in results:
        status = "[green]âœ… PASS[/green]" if success else "[red]âŒ FAIL[/red]"
        table.add_row(name, status)
        if success:
            passed += 1
    
    console.print(table)
    
    # ì „ì²´ ê²°ê³¼
    total = len(results)
    console.print(f"\n[bold]Overall: {passed}/{total} tests passed[/bold]")
    
    if passed == total:
        console.print("[bold green]ğŸ‰ All tests passed! Integration successful.[/bold green]")
    else:
        console.print(f"[bold yellow]âš ï¸ {total - passed} test(s) failed. Review the results above.[/bold yellow]")
    
    # ì¤‘ìš” ì°¸ê³ ì‚¬í•­
    console.print("\n[dim]Note: Some tests may show warnings if human_feedback data is not yet populated in the database.[/dim]")
    console.print("[dim]This is expected behavior for initial testing.[/dim]")


if __name__ == "__main__":
    asyncio.run(main())