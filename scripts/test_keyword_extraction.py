#!/usr/bin/env python3
"""
í‚¤ì›Œë“œ ì¶”ì¶œ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
meaningful_posê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
"""

import asyncio
import asyncpg
import os
import sys
from pathlib import Path
from dotenv import load_dotenv
from kiwipiepy import Kiwi
from rich.console import Console
from rich.table import Table

sys.path.append(str(Path(__file__).parent.parent))

load_dotenv()
console = Console()

def extract_keywords_current(kiwi, text):
    """í˜„ì¬ hybrid_search.pyì™€ ë™ì¼í•œ ë°©ì‹"""
    result = kiwi.tokenize(text)
    
    # í˜„ì¬ ì„¤ì •ëœ meaningful_pos
    meaningful_pos = {'NNG', 'NNP', 'NNB', 'VV', 'VA', 'VX', 'MM', 'MAG', 'SL', 'SH', 'SN', 'XR'}
    keywords = []
    
    for token in result:
        if hasattr(token, 'tag') and hasattr(token, 'form'):
            if token.tag in meaningful_pos:
                if token.tag.startswith('NN') or token.tag in {'SL', 'SH', 'SN'}:
                    if len(token.form) > 1 or token.tag in {'SL', 'SH', 'SN', 'NNB'}:
                        keywords.append((token.form, token.tag, 1.0))
                elif token.tag.startswith(('VV', 'VA')):
                    if len(token.form) >= 2:
                        keywords.append((token.form, token.tag, 0.7))
                else:
                    # ë‹¤ë¥¸ í’ˆì‚¬ë“¤ (VX, MM, MAG, XR)
                    keywords.append((token.form, token.tag, 0.5))
    
    return keywords

def extract_keywords_minimal(kiwi, text):
    """ìµœì†Œí•œì˜ í’ˆì‚¬ë§Œ ì‚¬ìš© (ëª…ì‚¬ ìœ„ì£¼)"""
    result = kiwi.tokenize(text)
    
    # ìµœì†Œí•œì˜ í’ˆì‚¬ ì„¸íŠ¸ (ëª…ì‚¬, ì¤‘ìš” ë™ì‚¬, ì™¸ë˜ì–´)
    minimal_pos = {'NNG', 'NNP', 'NNB', 'SL', 'SN'}  # VV, VA ì œì™¸
    keywords = []
    
    for token in result:
        if hasattr(token, 'tag') and hasattr(token, 'form'):
            if token.tag in minimal_pos:
                if len(token.form) > 1 or token.tag in {'SL', 'SN', 'NNB'}:
                    keywords.append((token.form, token.tag, 1.0))
    
    return keywords

def extract_keywords_balanced(kiwi, text):
    """ê· í˜•ì¡íŒ í’ˆì‚¬ ì„¸íŠ¸ (ì¶”ì²œ)"""
    result = kiwi.tokenize(text)
    
    # ê· í˜•ì¡íŒ í’ˆì‚¬ ì„¸íŠ¸ (ëª…ì‚¬, ì¤‘ìš” ë™ì‚¬/í˜•ìš©ì‚¬, ì™¸ë˜ì–´)
    balanced_pos = {'NNG', 'NNP', 'NNB', 'VV', 'VA', 'SL', 'SH', 'SN'}  # VX, MM, MAG, XR ì œì™¸
    keywords = []
    
    for token in result:
        if hasattr(token, 'tag') and hasattr(token, 'form'):
            if token.tag in balanced_pos:
                if token.tag.startswith('NN') or token.tag in {'SL', 'SH', 'SN'}:
                    if len(token.form) > 1 or token.tag in {'SL', 'SH', 'SN', 'NNB'}:
                        keywords.append((token.form, token.tag, 1.0))
                elif token.tag.startswith(('VV', 'VA')):
                    if len(token.form) >= 2:
                        keywords.append((token.form, token.tag, 0.7))
    
    return keywords

async def test_keyword_extraction():
    """í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    
    console.print("[bold blue]í‚¤ì›Œë“œ ì¶”ì¶œ ê²€ì¦ ì‹œì‘[/bold blue]\n")
    
    # Kiwi ì´ˆê¸°í™”
    kiwi = Kiwi()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ì—”ì§„ ì˜¤ì¼ êµì²´ ë°©ë²•",
        "ë¸Œë ˆì´í¬ íŒ¨ë“œë¥¼ êµí™˜í•˜ëŠ” ì ˆì°¨",
        "íƒ€ì´ì–´ ê³µê¸°ì•• í™•ì¸ ë° ì¡°ì •",
        "ì°¨ëŸ‰ ë°°í„°ë¦¬ê°€ ë°©ì „ë˜ì—ˆì„ ë•Œ ëŒ€ì²˜ë²•",
        "ì™€ì´í¼ ë¸”ë ˆì´ë“œ êµì²´ ì£¼ê¸°",
        "ì—ì–´ì»¨ í•„í„° ì²­ì†Œí•˜ê¸°",
        "ì´ ì°¨ëŸ‰ì˜ ì—°ë¹„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "ë§¤ìš° ì¤‘ìš”í•œ ì•ˆì „ ì ê²€ ì‚¬í•­ë“¤",
        "ìë™ì°¨ë¥¼ ê¹¨ë—í•˜ê²Œ ì„¸ì°¨í•˜ëŠ” ë°©ë²•"
    ]
    
    # ê° ì¿¼ë¦¬ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸
    for query in test_queries:
        console.print(f"\n[yellow]ì¿¼ë¦¬: '{query}'[/yellow]")
        
        # í˜„ì¬ ë°©ì‹
        current = extract_keywords_current(kiwi, query)
        console.print(f"\n[cyan]í˜„ì¬ ë°©ì‹ (ëª¨ë“  í’ˆì‚¬):[/cyan]")
        for word, tag, weight in current:
            console.print(f"  - '{word}' ({tag}) [weight: {weight}]")
        
        # ìµœì†Œ ë°©ì‹
        minimal = extract_keywords_minimal(kiwi, query)
        console.print(f"\n[green]ìµœì†Œ ë°©ì‹ (ëª…ì‚¬ë§Œ):[/green]")
        for word, tag, weight in minimal:
            console.print(f"  - '{word}' ({tag}) [weight: {weight}]")
        
        # ê· í˜• ë°©ì‹
        balanced = extract_keywords_balanced(kiwi, query)
        console.print(f"\n[magenta]ê· í˜• ë°©ì‹ (ì¶”ì²œ):[/magenta]")
        for word, tag, weight in balanced:
            console.print(f"  - '{word}' ({tag}) [weight: {weight}]")
        
        # ì°¨ì´ì  ë¶„ì„
        current_words = set(w for w, _, _ in current)
        minimal_words = set(w for w, _, _ in minimal)
        balanced_words = set(w for w, _, _ in balanced)
        
        noise_words = current_words - balanced_words
        if noise_words:
            console.print(f"\n[red]ë…¸ì´ì¦ˆ ê°€ëŠ¥ì„± (í˜„ì¬-ê· í˜•):[/red] {noise_words}")
        
        console.print("-" * 50)
    
    # DB ì—°ê²°í•´ì„œ ì‹¤ì œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    console.print("\n[bold yellow]ì‹¤ì œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸[/bold yellow]")
    
    connection_string = (
        f"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}"
        f"@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}"
    )
    
    conn = await asyncpg.connect(connection_string)
    
    try:
        test_query = "ì—”ì§„ ì˜¤ì¼ êµì²´ ë°©ë²•"
        
        # ê° ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰
        for method_name, keywords in [
            ("í˜„ì¬", extract_keywords_current(kiwi, test_query)),
            ("ìµœì†Œ", extract_keywords_minimal(kiwi, test_query)),
            ("ê· í˜•", extract_keywords_balanced(kiwi, test_query))
        ]:
            words = [w for w, _, _ in keywords]
            
            # tsquery ìƒì„± (ì²˜ìŒ 3ê°œë§Œ ì‚¬ìš©)
            if len(words) <= 2:
                search_query = ' & '.join(words[:3])
            else:
                # ì²« 2ê°œëŠ” AND, ë‚˜ë¨¸ì§€ëŠ” OR
                primary = ' & '.join(words[:2])
                optional = ' | '.join(words[2:3]) if len(words) > 2 else ""
                search_query = f"({primary})" + (f" | {optional}" if optional else "")
            
            # ê²€ìƒ‰ ì‹¤í–‰
            count = await conn.fetchval("""
                SELECT COUNT(*)
                FROM mvp_ddu_documents
                WHERE search_vector_korean @@ to_tsquery('simple', $1)
            """, search_query)
            
            console.print(f"\n[{method_name}] í‚¤ì›Œë“œ: {words[:3]}")
            console.print(f"  tsquery: '{search_query}'")
            console.print(f"  ë§¤ì¹­ ë¬¸ì„œ: {count}ê°œ")
    
    finally:
        await conn.close()
    
    console.print("\n[bold green]âœ… ê²€ì¦ ì™„ë£Œ[/bold green]")
    
    # ê¶Œì¥ì‚¬í•­
    console.print("\n[bold yellow]ğŸ’¡ ê¶Œì¥ì‚¬í•­:[/bold yellow]")
    console.print("1. VX (ë³´ì¡°ìš©ì–¸), MM (ê´€í˜•ì‚¬), MAG (ë¶€ì‚¬), XR (ì–´ê·¼)ì€ ì œì™¸ ì¶”ì²œ")
    console.print("2. ëª…ì‚¬(NN*) + ì™¸ë˜ì–´(SL, SN) + ì¤‘ìš” ë™ì‚¬/í˜•ìš©ì‚¬(VV, VA)ë§Œ í¬í•¨")
    console.print("3. ê· í˜•ì¡íŒ í’ˆì‚¬ ì„¸íŠ¸ ì‚¬ìš© ê¶Œì¥")

if __name__ == "__main__":
    asyncio.run(test_keyword_extraction())