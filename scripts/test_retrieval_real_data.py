"""
Retrieval System Test with Real Database Data
ì‹¤ì œ DBì— ì €ì¥ëœ ë¬¸ì„œë¥¼ ëŒ€ìƒìœ¼ë¡œ ë‹¤ì–‘í•œ ê²€ìƒ‰ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸
"""

import asyncio
import os
import sys
import json
import time
from pathlib import Path
from dotenv import load_dotenv
from typing import List, Dict, Any
import numpy as np
from rich.console import Console
from rich.table import Table
from rich import print as rprint
from rich.panel import Panel

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from ingest.database import DatabaseManager
from ingest.embeddings import DualLanguageEmbeddings
from retrieval.search_filter import MVPSearchFilter
from retrieval.hybrid_search import HybridSearch

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

console = Console()


class RetrievalTester:
    """ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.db_manager = None
        self.hybrid_search = None
        self.embeddings = DualLanguageEmbeddings()
        self.test_results = []
    
    async def initialize(self):
        """ì´ˆê¸°í™”"""
        self.db_manager = DatabaseManager()
        await self.db_manager.initialize()
        self.hybrid_search = HybridSearch(self.db_manager.pool)
    
    async def cleanup(self):
        """ì •ë¦¬"""
        if self.db_manager:
            await self.db_manager.close()
    
    def calculate_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not vec1 or not vec2:
            return 0.0
        vec1_np = np.array(vec1)
        vec2_np = np.array(vec2)
        return np.dot(vec1_np, vec2_np) / (np.linalg.norm(vec1_np) * np.linalg.norm(vec2_np))
    
    def print_detailed_results(self, results: List[Dict], max_display: int = 3, show_entity: bool = False):
        """ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ì¶œë ¥"""
        if not results:
            console.print("    [yellow]No results found[/yellow]")
            return
        
        console.print(f"\n  [green]Top {min(max_display, len(results))} Results:[/green]")
        
        for i, result in enumerate(results[:max_display], 1):
            console.print(f"\n  [bold]Result {i}:[/bold]")
            console.print(f"    ğŸ“„ Source: {result.get('source', 'N/A')}")
            console.print(f"    ğŸ“ Page: {result.get('page', 'N/A')} | Category: {result.get('category', 'N/A')}")
            
            # ì ìˆ˜ ì •ë³´ (ìˆëŠ” ê²½ìš°)
            if 'similarity' in result:
                console.print(f"    ğŸ¯ Similarity: {result['similarity']:.4f}")
            elif 'rank' in result:
                console.print(f"    ğŸ¯ Rank: {result['rank']:.4f}")
            elif 'rrf_score' in result:
                console.print(f"    ğŸ¯ RRF Score: {result['rrf_score']:.4f}")
            
            # ì½˜í…ì¸  í‘œì‹œ
            content = result.get('page_content', '')
            if not content:
                content = result.get('translation_text', '')
            if not content:
                content = result.get('contextualize_text', '')
            
            if content:
                # ë‚´ìš©ì„ 200ìë¡œ ì œí•œí•˜ì—¬ í‘œì‹œ
                display_content = content[:200] + "..." if len(content) > 200 else content
                # ì¤„ë°”ê¿ˆ ì œê±°í•˜ì—¬ ê¹”ë”í•˜ê²Œ í‘œì‹œ
                display_content = ' '.join(display_content.split())
                console.print(f"    ğŸ“ Content: [dim]{display_content}[/dim]")
            
            # ìº¡ì…˜ (ìˆëŠ” ê²½ìš°)
            if result.get('caption'):
                console.print(f"    ğŸ’¬ Caption: [cyan]{result['caption']}[/cyan]")
            
            # Entity ì •ë³´ (ìš”ì²­ëœ ê²½ìš°)
            if show_entity and result.get('entity'):
                try:
                    entity_data = json.loads(result['entity']) if isinstance(result['entity'], str) else result['entity']
                    if entity_data:
                        console.print(f"    ğŸ·ï¸  Entity Type: {entity_data.get('type', 'N/A')}")
                        if entity_data.get('title'):
                            console.print(f"    ğŸ·ï¸  Entity Title: {entity_data.get('title', '')[:100]}")
                except:
                    pass
    
    def evaluate_results(self, results: List[Dict], expected_keywords: List[str], test_name: str, language: str = "korean") -> Dict:
        """ê²€ìƒ‰ ê²°ê³¼ í‰ê°€"""
        evaluation = {
            "test_name": test_name,
            "total_results": len(results),
            "keyword_matches": 0,
            "relevance_score": 0.0,
            "top_results": []
        }
        
        if not results:
            return evaluation
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
        for result in results[:5]:  # ìƒìœ„ 5ê°œë§Œ í™•ì¸
            # ì–¸ì–´ì— ë”°ë¼ ì ì ˆí•œ í•„ë“œ ì„ íƒ
            if language == "english":
                # ì˜ì–´ ê²€ìƒ‰ì€ translation_text í•„ë“œ í™•ì¸
                content = result.get('translation_text', '') + ' ' + result.get('caption', '')
            else:
                # í•œêµ­ì–´ ê²€ìƒ‰ì€ page_contentì™€ contextualize_text í™•ì¸
                content = result.get('page_content', '') + ' ' + result.get('contextualize_text', '')
            
            content_lower = content.lower()
            
            matches = sum(1 for keyword in expected_keywords if keyword.lower() in content_lower)
            evaluation["keyword_matches"] += matches
            
            # ìƒìœ„ ê²°ê³¼ ì €ì¥
            evaluation["top_results"].append({
                "id": result.get('id'),
                "category": result.get('category'),
                "page": result.get('page'),
                "snippet": content[:100] + "..." if len(content) > 100 else content
            })
        
        # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° (í‚¤ì›Œë“œ ë§¤ì¹­ ë¹„ìœ¨)
        if expected_keywords and results:
            max_possible_matches = len(expected_keywords) * min(5, len(results))
            evaluation["relevance_score"] = evaluation["keyword_matches"] / max_possible_matches if max_possible_matches > 0 else 0
        
        return evaluation
    
    async def test_korean_keyword_search(self):
        """í•œêµ­ì–´ í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        console.print("\n[bold cyan]1. Korean Keyword Search Test[/bold cyan]")
        
        test_queries = [
            {
                "query": "ì•ˆì „ë²¨íŠ¸",
                "expected_keywords": ["ì•ˆì „ë²¨íŠ¸", "ì°©ìš©", "ì¢Œì„"],
                "description": "Safety belt search"
            },
            {
                "query": "ë¸Œë ˆì´í¬",
                "expected_keywords": ["ë¸Œë ˆì´í¬", "í˜ë‹¬", "ì£¼ì°¨"],
                "description": "Brake system search"
            },
            {
                "query": "ìš´ì „ ìì„¸",
                "expected_keywords": ["ìš´ì „", "ìì„¸", "ì¢Œì„", "ë“±ë°›ì´"],
                "description": "Driving posture search"
            }
        ]
        
        results_summary = []
        
        for test in test_queries:
            start_time = time.time()
            
            # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤í–‰
            async with self.db_manager.pool.acquire() as conn:
                # Kiwi í† í¬ë‚˜ì´ì €ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
                keywords = self.hybrid_search._extract_korean_keywords(test["query"])
                
                if keywords:
                    # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
                    search_query = ' & '.join(keywords)
                    
                    results = await conn.fetch("""
                        SELECT id, source, page, category, page_content, 
                               contextualize_text, caption, entity
                        FROM mvp_ddu_documents
                        WHERE search_vector_korean @@ to_tsquery('simple', $1)
                        ORDER BY ts_rank(search_vector_korean, to_tsquery('simple', $1)) DESC
                        LIMIT 10
                    """, search_query)
                    
                    elapsed = time.time() - start_time
                    
                    # ê²°ê³¼ í‰ê°€
                    results_list = [dict(r) for r in results]
                    evaluation = self.evaluate_results(results_list, test["expected_keywords"], test["description"], language="korean")
                    evaluation["query"] = test["query"]
                    evaluation["time"] = elapsed
                    evaluation["keywords_extracted"] = keywords
                    
                    results_summary.append(evaluation)
                    
                    # ê²°ê³¼ ì¶œë ¥
                    console.print(f"\n  Query: '{test['query']}'")
                    console.print(f"  Keywords: {', '.join(keywords)}")
                    console.print(f"  Results: {len(results)} documents")
                    console.print(f"  Relevance: {evaluation['relevance_score']:.2%}")
                    console.print(f"  Time: {elapsed:.3f}s")
                    
                    if results:
                        console.print(f"  Top result: {results[0]['category']} (page {results[0]['page']})")
                    
                    # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
                    self.print_detailed_results(results_list)
        
        self.test_results.append(("Korean Keyword Search", results_summary))
        return results_summary
    
    async def test_english_keyword_search(self):
        """ì˜ì–´ í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        console.print("\n[bold cyan]2. English Keyword Search Test[/bold cyan]")
        
        test_queries = [
            {
                "query": "seatbelt safety",
                "expected_keywords": ["seatbelt", "safety", "wear"],
                "description": "Seatbelt safety search"
            },
            {
                "query": "driving posture",
                "expected_keywords": ["driving", "posture", "seat"],
                "description": "Driving posture search"
            },
            {
                "query": "brake pedal",
                "expected_keywords": ["brake", "pedal", "parking"],
                "description": "Brake pedal search"
            }
        ]
        
        results_summary = []
        
        for test in test_queries:
            start_time = time.time()
            
            # ì˜ì–´ í‚¤ì›Œë“œ ê²€ìƒ‰
            async with self.db_manager.pool.acquire() as conn:
                keywords = test["query"].lower().split()
                search_query = ' & '.join(keywords)
                
                results = await conn.fetch("""
                    SELECT id, source, page, category, page_content,
                           translation_text, caption, entity
                    FROM mvp_ddu_documents
                    WHERE search_vector_english @@ to_tsquery('english', $1)
                    ORDER BY ts_rank(search_vector_english, to_tsquery('english', $1)) DESC
                    LIMIT 10
                """, search_query)
                
                elapsed = time.time() - start_time
                
                # ê²°ê³¼ í‰ê°€
                results_list = [dict(r) for r in results]
                evaluation = self.evaluate_results(
                    results_list, 
                    test["expected_keywords"], 
                    test["description"],
                    language="english"
                )
                evaluation["query"] = test["query"]
                evaluation["time"] = elapsed
                
                results_summary.append(evaluation)
                
                # ê²°ê³¼ ì¶œë ¥
                console.print(f"\n  Query: '{test['query']}'")
                console.print(f"  Results: {len(results)} documents")
                console.print(f"  Relevance: {evaluation['relevance_score']:.2%}")
                console.print(f"  Time: {elapsed:.3f}s")
                
                if results:
                    console.print(f"  Top result: {results[0]['category']} (page {results[0]['page']})")
                
                # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
                self.print_detailed_results(results_list)
        
        self.test_results.append(("English Keyword Search", results_summary))
        return results_summary
    
    async def test_semantic_search(self):
        """ì‹œë§¨í‹± ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        console.print("\n[bold cyan]3. Semantic Search Test[/bold cyan]")
        
        test_queries = [
            {
                "query": "ì°¨ëŸ‰ íƒ‘ìŠ¹ ì‹œ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì•ˆì „ ìˆ˜ì¹™",
                "language": "korean",
                "expected_keywords": ["ì•ˆì „ë²¨íŠ¸", "ì°©ìš©", "ì£¼í–‰"],
                "description": "Safety rules semantic search"
            },
            {
                "query": "How to properly wear a seatbelt",
                "language": "english",
                "expected_keywords": ["seatbelt", "wear", "properly"],
                "description": "Seatbelt instruction semantic search"
            },
            {
                "query": "ìš´ì „í•  ë•Œ í”¼í•´ì•¼ í•  ì‹ ë°œ",
                "language": "korean",
                "expected_keywords": ["í•˜ì´í", "ì‹ ë°œ", "ìš´ì „"],
                "description": "Driving shoes semantic search"
            }
        ]
        
        results_summary = []
        
        for test in test_queries:
            start_time = time.time()
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            if test["language"] == "korean":
                query_embedding = await self.embeddings.embeddings.aembed_query(test["query"])
                embedding_column = "embedding_korean"
            else:
                query_embedding = await self.embeddings.embeddings.aembed_query(test["query"])
                embedding_column = "embedding_english"
            
            # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
            async with self.db_manager.pool.acquire() as conn:
                # ì„ë² ë”©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                embedding_str = f"[{','.join(map(str, query_embedding))}]"
                
                results = await conn.fetch(f"""
                    SELECT id, source, page, category, page_content,
                           contextualize_text, translation_text, caption, entity,
                           1 - ({embedding_column} <=> $1::vector) as similarity
                    FROM mvp_ddu_documents
                    WHERE {embedding_column} IS NOT NULL
                    ORDER BY {embedding_column} <=> $1::vector
                    LIMIT 10
                """, embedding_str)
                
                elapsed = time.time() - start_time
                
                # ê²°ê³¼ í‰ê°€
                results_list = [dict(r) for r in results]
                evaluation = self.evaluate_results(
                    results_list,
                    test["expected_keywords"],
                    test["description"],
                    language=test["language"]
                )
                evaluation["query"] = test["query"]
                evaluation["language"] = test["language"]
                evaluation["time"] = elapsed
                
                if results:
                    evaluation["top_similarity"] = float(results[0]['similarity'])
                
                results_summary.append(evaluation)
                
                # ê²°ê³¼ ì¶œë ¥
                console.print(f"\n  Query: '{test['query']}'")
                console.print(f"  Language: {test['language']}")
                console.print(f"  Results: {len(results)} documents")
                
                if results:
                    console.print(f"  Top similarity: {results[0]['similarity']:.4f}")
                    console.print(f"  Relevance: {evaluation['relevance_score']:.2%}")
                    console.print(f"  Time: {elapsed:.3f}s")
                    console.print(f"  Top result: {results[0]['category']} (page {results[0]['page']})")
                
                # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
                self.print_detailed_results(results_list)
        
        self.test_results.append(("Semantic Search", results_summary))
        return results_summary
    
    async def test_filter_search(self):
        """í•„í„° ê¸°ë°˜ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        console.print("\n[bold cyan]4. Filter-based Search Test[/bold cyan]")
        
        test_filters = [
            {
                "filter": MVPSearchFilter(categories=["heading1"]),
                "description": "Heading1 category filter",
                "expected_count_min": 1
            },
            {
                "filter": MVPSearchFilter(categories=["figure", "table"]),
                "description": "Figure and Table filter",
                "expected_count_min": 1
            },
            {
                "filter": MVPSearchFilter(pages=[6]),
                "description": "Page 6 filter",
                "expected_count_min": 2
            },
            {
                "filter": MVPSearchFilter(
                    #categories=["figure"],
                    entity={"type": "image"}
                ),
                "description": "Figure with image entity filter",
                "expected_count_min": 1
            }
        ]
        
        results_summary = []
        
        for test in test_filters:
            start_time = time.time()
            
            # asyncpgìš© SQL ìƒì„±
            where_clause, params = test["filter"].to_sql_where_asyncpg()
            
            async with self.db_manager.pool.acquire() as conn:
                # í•„í„°ë§ëœ ê²€ìƒ‰
                results = await conn.fetch(f"""
                    SELECT id, source, page, category, page_content,
                           contextualize_text, caption, entity
                    FROM mvp_ddu_documents
                    WHERE {where_clause}
                    ORDER BY id
                    LIMIT 20
                """, *params)
                
                elapsed = time.time() - start_time
                
                # ê²°ê³¼ í‰ê°€
                evaluation = {
                    "description": test["description"],
                    "filter": test["filter"].to_dict(),
                    "total_results": len(results),
                    "expected_min": test["expected_count_min"],
                    "passed": len(results) >= test["expected_count_min"],
                    "time": elapsed
                }
                
                if results:
                    evaluation["sample_results"] = [
                        {
                            "id": r["id"],
                            "category": r["category"],
                            "page": r["page"]
                        } for r in results[:3]
                    ]
                
                results_summary.append(evaluation)
                
                # ê²°ê³¼ ì¶œë ¥
                console.print(f"\n  Filter: {test['description']}")
                console.print(f"  Results: {len(results)} documents")
                console.print(f"  Expected min: {test['expected_count_min']}")
                console.print(f"  Status: {'âœ… PASS' if evaluation['passed'] else 'âŒ FAIL'}")
                console.print(f"  Time: {elapsed:.3f}s")
                
                if results:
                    categories = set(r['category'] for r in results)
                    console.print(f"  Categories found: {', '.join(categories)}")
                    
                    # ìƒì„¸ ê²°ê³¼ ì¶œë ¥ (í•„í„° í…ŒìŠ¤íŠ¸ëŠ” ê°„ë‹¨íˆ 2ê°œë§Œ)
                    self.print_detailed_results([dict(r) for r in results], max_display=2)
        
        self.test_results.append(("Filter Search", results_summary))
        return results_summary
    
    async def test_hybrid_search(self):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        console.print("\n[bold cyan]5. Hybrid Search Test (Semantic + Keyword)[/bold cyan]")
        
        test_cases = [
            {
                "query": "ì•ˆì „ë²¨íŠ¸ ì°©ìš© ë°©ë²•",
                "filter": MVPSearchFilter(),
                "language": "korean",
                "description": "Seatbelt wearing method"
            },
            {
                "query": "vehicle safety instructions",
                "filter": MVPSearchFilter(categories=["heading1", "paragraph"]),
                "language": "english",
                "description": "Safety instructions with category filter"
            },
            {
                "query": "ë¸Œë ˆì´í¬ í˜ë‹¬",
                "filter": MVPSearchFilter(pages=[6]),
                "language": "korean",
                "description": "Brake pedal on specific page"
            }
        ]
        
        results_summary = []
        
        for test in test_cases:
            start_time = time.time()
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
            results = await self.hybrid_search.search(
                query=test["query"],
                filter=test["filter"],
                language=test["language"],
                top_k=10,
                semantic_weight=0.5,
                keyword_weight=0.5
            )
            
            elapsed = time.time() - start_time
            
            # ê²°ê³¼ í‰ê°€
            evaluation = {
                "description": test["description"],
                "query": test["query"],
                "language": test["language"],
                "filter": test["filter"].to_dict() if not test["filter"].is_empty() else "No filter",
                "total_results": len(results),
                "time": elapsed
            }
            
            if results:
                evaluation["top_results"] = []
                for r in results[:3]:
                    evaluation["top_results"].append({
                        "id": r.get("id"),
                        "category": r.get("category"),
                        "page": r.get("page"),
                        "rrf_score": r.get("rrf_score", 0),
                        "search_types": r.get("search_types", [])
                    })
            
            results_summary.append(evaluation)
            
            # ê²°ê³¼ ì¶œë ¥
            console.print(f"\n  Query: '{test['query']}'")
            console.print(f"  Language: {test['language']}")
            console.print(f"  Filter: {test['description']}")
            console.print(f"  Results: {len(results)} documents")
            console.print(f"  Time: {elapsed:.3f}s")
            
            if results and "rrf_score" in results[0]:
                console.print(f"  Top RRF score: {results[0]['rrf_score']:.4f}")
                console.print(f"  Search types: {', '.join(results[0].get('search_types', []))}")
            
            # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
            self.print_detailed_results(results)
        
        self.test_results.append(("Hybrid Search", results_summary))
        return results_summary
    
    async def test_entity_search(self):
        """Entity ê¸°ë°˜ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        console.print("\n[bold cyan]6. Entity-based Search Test[/bold cyan]")
        
        test_cases = [
            {
                "entity_filter": {"type": "image"},
                "description": "Search for image entities"
            },
            {
                "entity_filter": {"keywords": ["ì•ˆì „ë²¨íŠ¸"]},
                "description": "Search by entity keywords"
            },
            {
                "entity_filter": {"title": "ì•ˆì „"},
                "description": "Search by entity title"
            }
        ]
        
        results_summary = []
        
        for test in test_cases:
            start_time = time.time()
            
            # Entity í•„í„° ìƒì„±
            filter = MVPSearchFilter(entity=test["entity_filter"])
            where_clause, params = filter.to_sql_where_asyncpg()
            
            async with self.db_manager.pool.acquire() as conn:
                results = await conn.fetch(f"""
                    SELECT id, source, page, category, entity,
                           page_content, contextualize_text
                    FROM mvp_ddu_documents
                    WHERE {where_clause}
                    LIMIT 10
                """, *params)
                
                elapsed = time.time() - start_time
                
                # ê²°ê³¼ í‰ê°€
                evaluation = {
                    "description": test["description"],
                    "entity_filter": test["entity_filter"],
                    "total_results": len(results),
                    "time": elapsed
                }
                
                if results:
                    evaluation["entities_found"] = []
                    for r in results[:3]:
                        if r["entity"]:
                            entity_data = json.loads(r["entity"]) if isinstance(r["entity"], str) else r["entity"]
                            evaluation["entities_found"].append({
                                "id": r["id"],
                                "category": r["category"],
                                "entity_type": entity_data.get("type", "N/A"),
                                "entity_title": entity_data.get("title", "N/A")[:50]
                            })
                
                results_summary.append(evaluation)
                
                # ê²°ê³¼ ì¶œë ¥
                console.print(f"\n  Filter: {test['description']}")
                console.print(f"  Entity filter: {test['entity_filter']}")
                console.print(f"  Results: {len(results)} documents")
                console.print(f"  Time: {elapsed:.3f}s")
                
                if evaluation.get("entities_found"):
                    console.print(f"  Sample entities:")
                    for entity in evaluation["entities_found"]:
                        console.print(f"    - {entity['entity_type']}: {entity['entity_title']}")
                
                # ìƒì„¸ ê²°ê³¼ ì¶œë ¥ (Entity ì •ë³´ í¬í•¨)
                if results:
                    self.print_detailed_results([dict(r) for r in results], max_display=2, show_entity=True)
        
        self.test_results.append(("Entity Search", results_summary))
        return results_summary
    
    async def test_performance(self):
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        console.print("\n[bold cyan]7. Performance Test[/bold cyan]")
        
        performance_results = []
        
        # 1. ë‹¨ìˆœ ì¿¼ë¦¬ ì„±ëŠ¥
        console.print("\n  [yellow]Simple Query Performance[/yellow]")
        
        queries = ["ì•ˆì „ë²¨íŠ¸", "ë¸Œë ˆì´í¬", "ìš´ì „", "ì£¼ì°¨", "ì¢Œì„"]
        times = []
        result_counts = []
        
        for query in queries:
            start = time.time()
            
            async with self.db_manager.pool.acquire() as conn:
                results = await conn.fetch("""
                    SELECT id, page, category, page_content FROM mvp_ddu_documents
                    WHERE page_content ILIKE $1
                    LIMIT 10
                """, f"%{query}%")
            
            elapsed = time.time() - start
            times.append(elapsed)
            result_counts.append(len(results))
            console.print(f"    '{query}': {len(results)} results in {elapsed:.4f}s")
        
        avg_time = np.mean(times)
        avg_results = np.mean(result_counts)
        console.print(f"    Average: {avg_results:.1f} results in {avg_time:.4f}s")
        performance_results.append(("Simple Query", avg_time))
        
        # 2. ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥
        console.print("\n  [yellow]Vector Search Performance[/yellow]")
        
        test_embedding = [np.random.random() for _ in range(1536)]
        embedding_str = f"[{','.join(map(str, test_embedding))}]"
        
        start = time.time()
        async with self.db_manager.pool.acquire() as conn:
            await conn.fetch("""
                SELECT id FROM mvp_ddu_documents
                WHERE embedding_korean IS NOT NULL
                ORDER BY embedding_korean <=> $1::vector
                LIMIT 10
            """, embedding_str)
        
        vector_time = time.time() - start
        console.print(f"    Vector search time: {vector_time:.4f}s")
        performance_results.append(("Vector Search", vector_time))
        
        # 3. ë³µì¡í•œ í•„í„° ì„±ëŠ¥
        console.print("\n  [yellow]Complex Filter Performance[/yellow]")
        
        complex_filter = MVPSearchFilter(
            categories=["paragraph", "heading1"],
            pages=[1, 2, 3, 4, 5, 6],
            entity={"type": "image"}
        )
        
        where_clause, params = complex_filter.to_sql_where_asyncpg()
        
        start = time.time()
        async with self.db_manager.pool.acquire() as conn:
            await conn.fetch(f"""
                SELECT id FROM mvp_ddu_documents
                WHERE {where_clause}
            """, *params)
        
        filter_time = time.time() - start
        console.print(f"    Complex filter time: {filter_time:.4f}s")
        performance_results.append(("Complex Filter", filter_time))
        
        self.test_results.append(("Performance", performance_results))
        return performance_results
    
    def generate_report(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        console.print("\n[bold magenta]â•â•â• Test Results Summary â•â•â•[/bold magenta]\n")
        
        # ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í…Œì´ë¸”
        table = Table(title="Retrieval System Test Results")
        table.add_column("Test Category", style="cyan")
        table.add_column("Tests Run", justify="center")
        table.add_column("Avg Time", justify="center")
        table.add_column("Status", justify="center")
        
        for category, results in self.test_results:
            if category == "Performance":
                avg_time = np.mean([r[1] for r in results])
                status = "âœ…" if avg_time < 0.5 else "âš ï¸"
                table.add_row(
                    category,
                    str(len(results)),
                    f"{avg_time:.3f}s",
                    status
                )
            else:
                if results:
                    avg_time = np.mean([r.get("time", 0) for r in results])
                    # ì„±ê³µ ê¸°ì¤€: ê²°ê³¼ê°€ ìˆê³  ì‹œê°„ì´ ì ì ˆí•¨
                    all_pass = all(
                        r.get("total_results", 0) > 0 or r.get("passed", False)
                        for r in results
                    )
                    status = "âœ…" if all_pass else "âš ï¸"
                    
                    table.add_row(
                        category,
                        str(len(results)),
                        f"{avg_time:.3f}s",
                        status
                    )
        
        console.print(table)
        
        # ì£¼ìš” ë°œê²¬ì‚¬í•­
        console.print("\n[bold]Key Findings:[/bold]")
        
        findings = []
        
        # ê° í…ŒìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        for category, results in self.test_results:
            if category == "Korean Keyword Search" and results:
                avg_relevance = np.mean([r.get("relevance_score", 0) for r in results])
                findings.append(f"  â€¢ Korean search avg relevance: {avg_relevance:.1%}")
            
            elif category == "Semantic Search" and results:
                if any("top_similarity" in r for r in results):
                    avg_similarity = np.mean([r.get("top_similarity", 0) for r in results if "top_similarity" in r])
                    findings.append(f"  â€¢ Semantic search avg similarity: {avg_similarity:.3f}")
            
            elif category == "Filter Search" and results:
                passed = sum(1 for r in results if r.get("passed", False))
                findings.append(f"  â€¢ Filter tests passed: {passed}/{len(results)}")
        
        for finding in findings:
            console.print(finding)
        
        # ê¶Œì¥ì‚¬í•­
        console.print("\n[bold]Recommendations:[/bold]")
        
        # ì„±ëŠ¥ ë¶„ì„
        perf_results = dict(self.test_results).get("Performance", [])
        if perf_results:
            for test_name, test_time in perf_results:
                if test_time > 0.5:
                    console.print(f"  âš ï¸  {test_name} is slow ({test_time:.3f}s) - consider optimization")
                else:
                    console.print(f"  âœ… {test_name} performance is good ({test_time:.3f}s)")
        
        return self.test_results


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    console.print(Panel.fit(
        "[bold cyan]Retrieval System Test with Real Data[/bold cyan]\n"
        "Testing search functionality with actual database content",
        title="ğŸ” Retrieval Test Suite"
    ))
    
    tester = RetrievalTester()
    
    try:
        await tester.initialize()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
        stats = await tester.db_manager.get_table_stats()
        console.print(f"\n[bold]Database Status:[/bold]")
        console.print(f"  Total documents: {stats['total_documents']}")
        console.print(f"  Categories: {', '.join(f'{k}({v})' for k, v in list(stats['categories'].items())[:5])}")
        
        if stats['total_documents'] == 0:
            console.print("\n[red]âŒ No documents in database. Please run ingestion first.[/red]")
            return
        
        # ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        await tester.test_korean_keyword_search()
        await tester.test_english_keyword_search()
        await tester.test_semantic_search()
        await tester.test_filter_search()
        await tester.test_hybrid_search()
        await tester.test_entity_search()
        await tester.test_performance()
        
        # ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
        tester.generate_report()
        
    except Exception as e:
        console.print(f"\n[red]âŒ Test error: {e}[/red]")
        import traceback
        console.print(traceback.format_exc())
    
    finally:
        await tester.cleanup()
        console.print("\n[green]âœ… Test completed[/green]")


if __name__ == "__main__":
    # í™˜ê²½ ë³€ìˆ˜ ì²´í¬
    required_env = ["DB_HOST", "DB_PORT", "DB_NAME", "DB_USER", "DB_PASSWORD", "OPENAI_API_KEY"]
    missing = [var for var in required_env if not os.getenv(var)]
    
    if missing:
        console.print(f"[red]âŒ Missing environment variables: {', '.join(missing)}[/red]")
        sys.exit(1)
    
    asyncio.run(main())